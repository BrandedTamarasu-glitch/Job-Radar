---
phase: 33-scoring-configuration-backend
plan: 02
type: tdd
wave: 2
depends_on: ["33-01"]
files_modified:
  - job_radar/scoring.py
  - tests/test_scoring.py
autonomous: true

must_haves:
  truths:
    - "Scoring engine uses profile scoring_weights when provided instead of hardcoded values"
    - "Scoring engine falls back to DEFAULT_SCORING_WEIGHTS when profile has no scoring_weights"
    - "Staffing firm preference applies post-scoring adjustment: boost(+0.5), neutral(0), penalize(-1.0)"
    - "Old hardcoded +4.5 staffing firm boost in _score_response_likelihood is removed"
    - "Scores for existing profiles with default weights are identical to previous hardcoded behavior"
  artifacts:
    - path: "job_radar/scoring.py"
      provides: "Configurable weighted scoring with profile-based weights and staffing preference"
      contains: "scoring_weights"
    - path: "tests/test_scoring.py"
      provides: "Tests for configurable weights, staffing preference, score stability"
      contains: "test_score_job_uses_profile_weights"
  key_links:
    - from: "job_radar/scoring.py"
      to: "job_radar/profile_manager.py"
      via: "imports DEFAULT_SCORING_WEIGHTS for fallback"
      pattern: "from .profile_manager import DEFAULT_SCORING_WEIGHTS"
    - from: "job_radar/scoring.py"
      to: "score_job"
      via: "profile.get('scoring_weights') replaces hardcoded 0.25/0.15/etc"
      pattern: "profile.get.*scoring_weights"
---

<objective>
Replace hardcoded scoring weights with profile-based configurable weights and add staffing firm preference post-scoring adjustment.

Purpose: Allow users to customize how much each scoring component (skills, title, seniority, location, domain, response) contributes to the overall job score. Replace the old hardcoded +4.5 staffing firm boost with a configurable preference system.

Output: Updated scoring.py using profile weights with defense-in-depth fallback, staffing preference post-scoring adjustment, and comprehensive test coverage.
</objective>

<execution_context>
@/home/corye/.claude/get-shit-done/workflows/execute-plan.md
@/home/corye/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/33-scoring-configuration-backend/33-RESEARCH.md
@.planning/phases/33-scoring-configuration-backend/33-01-SUMMARY.md
@job_radar/scoring.py
@job_radar/staffing_firms.py
@tests/test_scoring.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: RED - Write failing tests for configurable weights and staffing preference</name>
  <files>tests/test_scoring.py</files>
  <action>
Add the following test sections to `tests/test_scoring.py`:

**Section: "Configurable scoring weights" (after existing tests):**

1. `test_score_job_uses_profile_weights` - Create a profile with custom scoring_weights that heavily weight skill_match (0.60) and minimize others (0.08 each for title, seniority, location, domain, response -- sums to 1.0). Score a job that has perfect skill match (5.0) but poor title match (1.5). Assert overall score is higher than scoring the same job with default weights (where skill_match is only 0.25). This proves weights are being used.

2. `test_score_job_default_weights_fallback` - Create a profile WITHOUT scoring_weights key. Score a job. Assert it returns a valid score (no KeyError, no crash). This proves defense-in-depth fallback works.

3. `test_score_stability_default_weights` - CRITICAL TEST. Create a profile with scoring_weights matching DEFAULT_SCORING_WEIGHTS exactly. Score a specific job. Then create an identical profile WITHOUT scoring_weights. Score the same job. Assert both overall scores are IDENTICAL. This proves score stability on migration.

4. `test_score_job_custom_weights_math` - Create a profile with known weights: skill_match=0.50, title_relevance=0.10, seniority=0.10, location=0.10, domain=0.10, response_likelihood=0.10. Mock/craft a job where we can predict component scores. Verify the weighted sum matches the expected calculation. (Use a simple job that produces known component scores to validate the math.)

**Section: "Staffing firm preference":**

5. `test_staffing_boost_adds_half_point` - Profile with staffing_preference="boost". Score a job from a known staffing firm (use company="Robert Half"). Assert score includes a +0.5 adjustment. Compare against same job scored with staffing_preference="neutral" and verify boost version is ~0.5 higher.

6. `test_staffing_penalize_subtracts_one_point` - Profile with staffing_preference="penalize". Score a staffing firm job. Assert score is ~1.0 lower than neutral scoring.

7. `test_staffing_neutral_no_adjustment` - Profile with staffing_preference="neutral". Score a staffing firm job. Assert NO adjustment is applied (score equals what it would be without any staffing logic).

8. `test_staffing_preference_missing_defaults_neutral` - Profile without staffing_preference key. Score a staffing firm job. Assert no adjustment (same as neutral). This proves graceful fallback.

9. `test_staffing_boost_capped_at_5` - Profile with staffing_preference="boost". Score a staffing firm job that already scores close to 5.0 (perfect match on everything). Assert overall score does not exceed 5.0.

10. `test_staffing_penalize_floored_at_1` - Profile with staffing_preference="penalize". Score a staffing firm job that scores low (poor match). Assert overall score does not go below 1.0.

**Section: "Response likelihood without hardcoded staffing boost":**

11. `test_response_likelihood_staffing_no_boost` - Call `_score_response_likelihood()` directly with a staffing firm job. Assert the score is 3.0 (base) NOT 4.5 (the old hardcoded boost has been removed). The staffing firm handling now lives in score_job(), not _score_response_likelihood().

Use the existing `sample_profile` and `job_factory` fixtures from conftest.py.

Run `pytest tests/test_scoring.py -x` -- new tests MUST FAIL (RED phase).

Commit: `test(33-02): add failing tests for configurable weights and staffing preference`
  </action>
  <verify>Run `pytest tests/test_scoring.py -x` and confirm new tests fail. Existing scoring tests must still pass.</verify>
  <done>11+ new test cases covering configurable weights, score stability, staffing preference presets, cap/floor bounds, and removal of hardcoded staffing boost.</done>
</task>

<task type="auto">
  <name>Task 2: GREEN + REFACTOR - Implement configurable weights and staffing preference in scoring.py</name>
  <files>job_radar/scoring.py, tests/test_scoring.py</files>
  <action>
Update `job_radar/scoring.py` to make all tests pass:

**1. Import DEFAULT_SCORING_WEIGHTS from profile_manager:**
```python
from .profile_manager import DEFAULT_SCORING_WEIGHTS
```

**2. Update score_job() to use profile weights:**
Replace the hardcoded weighted total (lines 47-54):
```python
# Weighted total
overall = (
    scores["skill_match"]["score"] * 0.25
    + scores["title_relevance"]["score"] * 0.15
    + scores["seniority"]["score"] * 0.15
    + scores["location"]["score"] * 0.15
    + scores["domain"]["score"] * 0.10
    + scores["response"]["score"] * 0.20
)
```

With configurable weights using defense-in-depth fallback:
```python
# Get weights from profile with fallback to defaults (defense-in-depth)
weights = profile.get("scoring_weights", DEFAULT_SCORING_WEIGHTS)

# Weighted total using configurable weights
overall = (
    scores["skill_match"]["score"] * weights.get("skill_match", 0.25)
    + scores["title_relevance"]["score"] * weights.get("title_relevance", 0.15)
    + scores["seniority"]["score"] * weights.get("seniority", 0.15)
    + scores["location"]["score"] * weights.get("location", 0.15)
    + scores["domain"]["score"] * weights.get("domain", 0.10)
    + scores["response"]["score"] * weights.get("response_likelihood", 0.20)
)
```

Note: Each individual .get() call has its own default as triple-fallback protection.

**3. Add staffing preference post-scoring adjustment:**
After the weighted sum calculation but BEFORE comp penalty, add:
```python
# Staffing firm preference (post-scoring adjustment, NOT a weight component)
staffing_pref = profile.get("staffing_preference", "neutral")
if is_staffing_firm(job.company):
    if staffing_pref == "boost":
        overall = min(5.0, overall + 0.5)
        scores["staffing_note"] = "Staffing firm (boosted +0.5)"
    elif staffing_pref == "penalize":
        overall = max(1.0, overall - 1.0)
        scores["staffing_note"] = "Staffing firm (penalized -1.0)"
    # "neutral" = no adjustment, staffing firm treated same as direct employer
```

**4. Remove hardcoded +4.5 staffing boost from _score_response_likelihood():**
In `_score_response_likelihood()` (around line 500-503), REMOVE this block:
```python
# Staffing firms: high response likelihood
if is_staffing_firm(job.company):
    score = 4.5
    reasons.append("Staffing firm (high placement incentive)")
```

This is critical -- leaving the old boost creates a DOUBLE-boost bug. Staffing firm handling is now exclusively in score_job() via the configurable staffing_preference.

**5. IMPORTANT: After removing the staffing boost from _score_response_likelihood(), verify that the function still works correctly.** The base score starts at 3.0 and other adjustments (direct email, HN Hiring, RemoteOK, small team, large enterprise) remain unchanged.

Run `pytest tests/test_scoring.py -v` -- ALL tests MUST pass (GREEN phase).
Run `pytest` -- full suite passes (zero regressions).

**REFACTOR (if needed):** If any existing scoring tests assumed the old +4.5 staffing boost in _score_response_likelihood, update them to reflect the new behavior (staffing firms score 3.0 base in response_likelihood, with separate staffing_preference adjustment in score_job). Update test expectations accordingly.

Commit: `feat(33-02): replace hardcoded weights with profile-based configurable scoring`
  </action>
  <verify>Run `pytest tests/test_scoring.py -v` -- all tests pass. Run `pytest` -- full test suite passes (482+ tests, zero regressions).</verify>
  <done>score_job() reads scoring_weights from profile with DEFAULT_SCORING_WEIGHTS fallback. Staffing preference applies post-scoring (+0.5 boost, 0 neutral, -1.0 penalize). Old hardcoded +4.5 staffing boost removed from _score_response_likelihood(). Score stability verified -- default weights produce identical scores to old hardcoded behavior. All tests pass.</done>
</task>

</tasks>

<verification>
1. `pytest tests/test_scoring.py -v` -- all tests pass including 11+ new configurable weight and staffing preference tests
2. `pytest` -- full test suite passes (482+ tests, zero regressions)
3. Score stability check: Score identical job with default-weighted profile vs no-weights profile, assert identical results
4. Verify `_score_response_likelihood()` no longer boosts staffing firms (base score 3.0 for all companies)
</verification>

<success_criteria>
- score_job() uses profile["scoring_weights"] when present, falls back to DEFAULT_SCORING_WEIGHTS
- Individual weight .get() calls provide triple-fallback protection
- Staffing firm preference: boost(+0.5), neutral(0), penalize(-1.0) as post-scoring adjustment
- Old +4.5 hardcoded staffing boost REMOVED from _score_response_likelihood()
- No double-boost bug (only one staffing adjustment path)
- Default weights produce scores identical to previous hardcoded behavior
- Overall score capped at 5.0 and floored at 1.0 for all adjustments
- All existing + new tests pass with zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/33-scoring-configuration-backend/33-02-SUMMARY.md`
</output>

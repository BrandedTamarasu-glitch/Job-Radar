---
phase: 09-report-enhancement
plan: 03
type: execute
wave: 3
depends_on: ["09-01", "09-02"]
files_modified:
  - tests/test_report.py
  - tests/test_browser.py
autonomous: true

must_haves:
  truths:
    - "HTML report generation produces valid HTML with Bootstrap 5 markup"
    - "Markdown report generation unchanged (no regressions)"
    - "generate_report() returns dict with markdown, html, and stats keys"
    - "is_headless_environment() correctly detects CI/server environments"
    - "open_report_in_browser() uses pathlib.as_uri() and handles failures gracefully"
    - "--no-open flag and auto_open_browser config key affect browser behavior"
  artifacts:
    - path: "tests/test_report.py"
      provides: "Tests for dual-format report generation"
      contains: "test_generate_report"
    - path: "tests/test_browser.py"
      provides: "Tests for browser utilities and headless detection"
      contains: "test_is_headless"
  key_links:
    - from: "tests/test_report.py"
      to: "job_radar/report.py"
      via: "Tests call generate_report() and verify HTML/Markdown output"
      pattern: "generate_report"
    - from: "tests/test_browser.py"
      to: "job_radar/browser.py"
      via: "Tests call is_headless_environment() and open_report_in_browser()"
      pattern: "is_headless_environment|open_report_in_browser"
---

<objective>
Add comprehensive tests for Phase 9 report enhancement: HTML generation, browser utilities, and CLI integration.

Purpose: Verify all Phase 9 functionality works correctly and prevent regressions.
Output: Two new test files covering report generation and browser utilities.
</objective>

<execution_context>
@/Users/coryebert/.claude/get-shit-done/workflows/execute-plan.md
@/Users/coryebert/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-report-enhancement/09-CONTEXT.md
@.planning/phases/09-report-enhancement/09-01-SUMMARY.md
@.planning/phases/09-report-enhancement/09-02-SUMMARY.md
@job_radar/report.py
@job_radar/browser.py
@job_radar/search.py
@tests/test_scoring.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test_report.py for dual-format report generation</name>
  <files>tests/test_report.py</files>
  <action>
Create `tests/test_report.py` with pytest tests for report.py. Use the existing test patterns from tests/test_scoring.py (pytest fixtures, parametrize, etc.).

**Test fixtures:**
- `sample_profile` fixture: dict with name, target_titles, core_skills, level, years_experience, location, arrangement, dealbreakers, highlights
- `sample_scored_results` fixture: list of 3 dicts with {"job": JobResult(...), "score": {"overall": X, "recommendation": "...", "components": {...}}, "is_new": bool}. Use dataclass `JobResult` from `job_radar.sources`. Include one high score (4.0+), one medium (3.5+), one low (2.5).
- `sample_manual_urls` fixture: list of 2 manual URL dicts
- `output_dir` fixture: use `tmp_path` to create isolated output directory

**Tests to write:**

1. `test_generate_report_returns_dict(sample_profile, sample_scored_results, sample_manual_urls, tmp_path)`:
   - Call `generate_report()` with sample data and output_dir=str(tmp_path)
   - Assert result is a dict with keys "markdown", "html", "stats"
   - Assert stats has "total", "new", "high_score" keys

2. `test_generate_report_creates_both_files(sample_profile, sample_scored_results, sample_manual_urls, tmp_path)`:
   - Call generate_report()
   - Assert both result["markdown"] and result["html"] paths exist on disk
   - Assert markdown file ends with .md, html file ends with .html

3. `test_html_report_contains_bootstrap(sample_profile, sample_scored_results, sample_manual_urls, tmp_path)`:
   - Generate report, read HTML file
   - Assert "bootstrap" in content (CDN link)
   - Assert "data-bs-theme" in content (dark mode)
   - Assert 'name="viewport"' in content (responsive)
   - Assert 'name="color-scheme"' in content (color scheme meta)

4. `test_html_report_contains_job_data(sample_profile, sample_scored_results, sample_manual_urls, tmp_path)`:
   - Generate report, read HTML file
   - Assert profile name appears in HTML
   - Assert job titles from sample data appear in HTML
   - Assert score badges appear (e.g., "bg-success", "bg-warning")

5. `test_html_report_escapes_html_entities(tmp_path)`:
   - Create profile with name containing `<script>alert('xss')</script>`
   - Generate report
   - Assert `&lt;script&gt;` in HTML (escaped), NOT `<script>` (raw)

6. `test_markdown_report_still_generated(sample_profile, sample_scored_results, sample_manual_urls, tmp_path)`:
   - Generate report, read Markdown file
   - Assert starts with `# Job Search Results`
   - Assert contains "## Candidate Profile Summary"
   - Assert contains "## All Results"

7. `test_file_naming_uses_timestamp(sample_profile, sample_scored_results, sample_manual_urls, tmp_path)`:
   - Generate report
   - Assert filenames match `jobs_YYYY-MM-DD_HH-MM` pattern (regex check)

8. `test_report_stats_accuracy(sample_profile, sample_scored_results, sample_manual_urls, tmp_path)`:
   - Generate report with known data (1 high score, 1 medium, 1 low)
   - Assert stats["total"] matches expected count
   - Assert stats["high_score"] counts only >= 3.5

9. `test_empty_results_generates_reports(sample_profile, sample_manual_urls, tmp_path)`:
   - Generate report with empty scored_results list
   - Assert both files created
   - Assert HTML contains "No results" message

10. `test_generate_report_creates_output_dir(sample_profile, sample_scored_results, sample_manual_urls, tmp_path)`:
    - Call with output_dir that doesn't exist yet
    - Assert directory created and files generated

IMPORTANT: Use `from job_radar.sources import JobResult` to create test data. Use `dataclasses.dataclass` fields matching the actual JobResult class (title, company, location, arrangement, salary, date_posted, description, url, source, apply_info, employment_type, parse_confidence).
  </action>
  <verify>
Run: `python -m pytest tests/test_report.py -v` — all tests pass
  </verify>
  <done>
10 tests verify dual-format report generation: return type, file creation, Bootstrap markup, job data in HTML, HTML escaping, Markdown regression, timestamp naming, stats accuracy, empty results, and directory creation.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create test_browser.py for browser utilities and config integration</name>
  <files>tests/test_browser.py</files>
  <action>
Create `tests/test_browser.py` with pytest tests for browser.py and config integration.

**Tests for is_headless_environment():**

1. `test_headless_ci_env(monkeypatch)`:
   - Set `CI=true` env var via monkeypatch
   - Assert `is_headless_environment()` returns True

2. `test_headless_github_actions(monkeypatch)`:
   - Set `GITHUB_ACTIONS=true`
   - Assert returns True

3. `test_headless_jenkins(monkeypatch)`:
   - Set `BUILD_ID=123`
   - Assert returns True

4. `test_headless_no_display_linux(monkeypatch)`:
   - Set `os.name` to "posix", remove DISPLAY env var, set `sys.platform` to "linux"
   - Assert returns True

5. `test_not_headless_macos_no_display(monkeypatch)`:
   - Set `sys.platform` to "darwin", remove DISPLAY env var
   - Verify behavior is correct for macOS (macOS doesn't use X11 by default)

6. `test_not_headless_normal_desktop(monkeypatch)`:
   - Clear CI, GITHUB_ACTIONS, BUILD_ID env vars
   - Set DISPLAY=":0" (simulating desktop)
   - Assert returns False

**Tests for open_report_in_browser():**

7. `test_open_disabled_by_user()`:
   - Call `open_report_in_browser("/tmp/test.html", auto_open=False)`
   - Assert result["opened"] is False
   - Assert "disabled" in result["reason"]

8. `test_open_in_headless_skips(monkeypatch)`:
   - Set `CI=true`
   - Call with auto_open=True
   - Assert result["opened"] is False
   - Assert "headless" in result["reason"]

9. `test_open_success(monkeypatch, tmp_path)`:
   - Create a real HTML file in tmp_path
   - Clear headless env vars, set DISPLAY=":0"
   - Monkeypatch `webbrowser.open` to return True
   - Call open_report_in_browser with the file path
   - Assert result["opened"] is True

10. `test_open_browser_failure(monkeypatch, tmp_path)`:
    - Create a real HTML file in tmp_path
    - Clear headless env vars, set DISPLAY=":0"
    - Monkeypatch `webbrowser.open` to return False
    - Assert result["opened"] is False
    - Assert "not available" in result["reason"]

11. `test_open_browser_exception(monkeypatch, tmp_path)`:
    - Monkeypatch `webbrowser.open` to raise OSError
    - Assert result["opened"] is False
    - Assert "error" in result["reason"]

**Tests for config integration:**

12. `test_config_recognizes_auto_open_browser()`:
    - `from job_radar.config import KNOWN_KEYS`
    - Assert `"auto_open_browser" in KNOWN_KEYS`

13. `test_config_known_keys_count()`:
    - Assert `len(KNOWN_KEYS) == 5` (min_score, new_only, output, profile_path, auto_open_browser)

Use `monkeypatch` for all environment variable manipulation. Use `monkeypatch.delenv()` with `raising=False` to safely remove env vars that may not exist.
  </action>
  <verify>
Run: `python -m pytest tests/test_browser.py -v` — all tests pass
Run: `python -m pytest tests/ -x -q` — full suite passes (no regressions)
  </verify>
  <done>
13 tests verify browser utilities: headless detection for CI/GitHub/Jenkins/Linux/macOS, browser opening with success/failure/exception/disabled/headless cases, and config key integration. Full test suite passes.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_report.py -v` — all report tests pass
2. `python -m pytest tests/test_browser.py -v` — all browser tests pass
3. `python -m pytest tests/ -x -q` — full suite passes with no regressions
4. Test count: Previous 118 tests + ~23 new = ~141 total
</verification>

<success_criteria>
- tests/test_report.py has 10 tests covering dual-format generation, HTML content, escaping, stats
- tests/test_browser.py has 13 tests covering headless detection, browser opening, config integration
- All new tests pass
- All existing tests pass (no regressions from report.py return type change)
- No flaky tests (all use monkeypatch/tmp_path for isolation)
</success_criteria>

<output>
After completion, create `.planning/phases/09-report-enhancement/09-03-SUMMARY.md`
</output>

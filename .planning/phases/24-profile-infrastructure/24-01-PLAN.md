---
phase: 24-profile-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - job_radar/profile_manager.py
  - job_radar/paths.py
autonomous: true

must_haves:
  truths:
    - "Profile saves never produce corrupted JSON files even if the process is interrupted mid-write"
    - "A timestamped backup copy is created automatically before every profile update"
    - "Old backups beyond the 10 most recent are deleted automatically"
    - "Profile JSON includes a schema_version field set to 1 on every save"
    - "Invalid profile data is rejected with a clear error message before any file is written"
  artifacts:
    - path: "job_radar/profile_manager.py"
      provides: "Centralized profile I/O with atomic writes, backups, validation, schema versioning"
      exports: ["load_profile", "save_profile", "validate_profile", "ProfileValidationError", "MissingFieldError", "InvalidTypeError", "ProfileNotFoundError"]
      min_lines: 120
    - path: "job_radar/paths.py"
      provides: "get_backup_dir() function for backup directory resolution"
      contains: "def get_backup_dir"
  key_links:
    - from: "job_radar/profile_manager.py"
      to: "job_radar/paths.py"
      via: "import get_backup_dir for backup directory"
      pattern: "from \\.paths import get_backup_dir"
    - from: "job_radar/profile_manager.py save_profile()"
      to: "job_radar/profile_manager.py validate_profile()"
      via: "validate before write"
      pattern: "validate_profile\\(profile_data\\)"
    - from: "job_radar/profile_manager.py save_profile()"
      to: "job_radar/profile_manager.py _rotate_backups()"
      via: "rotate after backup creation"
      pattern: "_rotate_backups\\("
    - from: "job_radar/profile_manager.py load_profile()"
      to: "job_radar/profile_manager.py save_profile()"
      via: "auto-save on schema migration from v0 to v1"
      pattern: "save_profile\\(profile"
---

<objective>
Create the centralized profile_manager.py module with atomic writes, automatic timestamped backups with rotation, schema versioning, and validation with a custom exception hierarchy.

Purpose: This module becomes the single source of truth for all profile I/O operations in the codebase, replacing scattered load/validate/write logic in wizard.py and search.py.

Output: `job_radar/profile_manager.py` (new module) and updated `job_radar/paths.py` (new get_backup_dir function).
</objective>

<execution_context>
@/home/corye/.claude/get-shit-done/workflows/execute-plan.md
@/home/corye/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-profile-infrastructure/24-RESEARCH.md
@job_radar/paths.py
@job_radar/wizard.py (lines 145-186 for _write_json_atomic pattern to extract)
@job_radar/search.py (lines 237-295 for load_profile validation logic to centralize)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create profile_manager.py with exception hierarchy, validation, atomic write, backup rotation, and schema versioning</name>
  <files>job_radar/profile_manager.py, job_radar/paths.py</files>
  <action>
**paths.py** -- Add a `get_backup_dir()` function that returns `get_data_dir() / "backups"` and creates the directory if it does not exist (same pattern as `get_data_dir()`). Place it after the existing `get_data_dir()` function.

**profile_manager.py** -- Create new module with this structure (all stdlib, no new dependencies):

1. **Module docstring**: `"""Centralized profile I/O with atomic writes, backups, validation, and schema versioning."""`

2. **Imports**: `json`, `os`, `tempfile`, `logging` from stdlib; `Path` from `pathlib`; `datetime` from `datetime`. Relative import: `from .paths import get_data_dir, get_backup_dir`.

3. **Logger**: `log = logging.getLogger(__name__)`

4. **Constants**: `CURRENT_SCHEMA_VERSION = 1`

5. **Exception hierarchy** (4 classes):
   - `ProfileValidationError(Exception)` -- base exception with plain message
   - `MissingFieldError(ProfileValidationError)` -- takes `field: str` param, message: `"Missing required field: '{field}'"`, stores `self.field`
   - `InvalidTypeError(ProfileValidationError)` -- takes `field: str, expected: str, got: type` params, message: `"Field '{field}' must be {expected}, got {got.__name__}"`, stores `self.field`
   - `ProfileNotFoundError(ProfileValidationError)` -- takes `path: str` param, message: `"Profile not found: {path}"`

6. **`validate_profile(profile: dict) -> None`**:
   - If `profile` is not a dict, raise `InvalidTypeError("profile", "dict", type(profile))`
   - Required fields: `["name", "target_titles", "core_skills"]`. For each missing, collect into list and raise single `MissingFieldError` with comma-joined field names (match existing search.py behavior of reporting all missing at once)
   - `target_titles`: must be a non-empty list, else raise `InvalidTypeError("target_titles", "non-empty list", type(...))`
   - `core_skills`: must be a non-empty list, else raise `InvalidTypeError("core_skills", "non-empty list", type(...))`
   - `name`: must be a non-empty string, else raise `InvalidTypeError("name", "non-empty string", type(...))`
   - Optional field validation (only if key present):
     - `years_experience`: must be int, 0-50 range. Raise `ProfileValidationError` with specific message if out of range.
     - `comp_floor`: must be int or float, 0-1_000_000 range. Raise `ProfileValidationError` with specific message.
     - `arrangement`: must be a list. Raise `InvalidTypeError` if not.
     - `level`: must be a string. Raise `InvalidTypeError` if not.
     - `dealbreakers`: must be a list. Raise `InvalidTypeError` if not.
     - `domain_expertise`: must be a list. Raise `InvalidTypeError` if not.
   - Do NOT validate `schema_version` here (that is handled by load_profile migration logic)

7. **`_rotate_backups(backup_dir: Path, max_backups: int = 10) -> None`**:
   - Glob `backup_dir / "profile_*.json"`, sort by `st_mtime` descending (newest first)
   - Delete (`.unlink()`) all beyond `max_backups`
   - Log debug message for each deleted backup

8. **`save_profile(profile_data: dict, profile_path: Path | None = None) -> Path`**:
   - If `profile_path` is None, default to `get_data_dir() / "profile.json"`
   - Call `validate_profile(profile_data)` FIRST -- never write invalid data
   - Ensure `schema_version` is set: `profile_data["schema_version"] = CURRENT_SCHEMA_VERSION`
   - If profile_path already exists, create timestamped backup:
     - Use `datetime.utcnow().strftime("%Y%m%d_%H%M%S_%f")` (include microseconds per research pitfall 4 to avoid collision)
     - Backup path: `get_backup_dir() / f"profile_{timestamp}.json"`
     - Copy current file content to backup path (simple read+write, not atomic -- backup corruption is recoverable)
     - Call `_rotate_backups(get_backup_dir())`
     - If backup creation fails, let the exception propagate (abort save per research recommendation)
   - Atomic write (extracted from wizard.py `_write_json_atomic()`):
     - `profile_path.parent.mkdir(parents=True, exist_ok=True)`
     - `tempfile.mkstemp(dir=profile_path.parent, prefix=profile_path.name + ".", suffix=".tmp")`
     - Write with `json.dump(profile_data, f, indent=2, ensure_ascii=False)`, `f.flush()`, `os.fsync(f.fileno())`
     - `Path(tmp_path).replace(profile_path)` for atomic rename
     - On exception: clean up temp file with `os.unlink(tmp_path)`, re-raise
   - Log info: `"Profile saved: {profile_path}"`
   - Return `profile_path`

9. **`load_profile(profile_path: Path | None = None) -> dict`**:
   - If `profile_path` is None, default to `get_data_dir() / "profile.json"`
   - If path does not exist, raise `ProfileNotFoundError(str(profile_path))`
   - Try `json.load()`, on `JSONDecodeError` raise `ProfileValidationError(f"Invalid JSON in profile: {e.msg} (line {e.lineno})")`
   - Schema migration: `schema_version = profile.get("schema_version", 0)` (compare as int per research pitfall 3)
     - If `schema_version == 0`: set `profile["schema_version"] = CURRENT_SCHEMA_VERSION`, call `save_profile(profile, profile_path)` to auto-save migration, log info
     - If `schema_version > CURRENT_SCHEMA_VERSION`: raise `ProfileValidationError("Profile schema version {schema_version} is newer than supported (max: {CURRENT_SCHEMA_VERSION}). Please update Job Radar.")`
   - Call `validate_profile(profile)`
   - Return profile dict

Follow existing codebase conventions: module-level logger, underscore prefix for private functions, type hints on all public function parameters, docstrings for public functions.
  </action>
  <verify>
Run: `cd /home/corye/Claude/Job-Radar && python -c "from job_radar.profile_manager import load_profile, save_profile, validate_profile, ProfileValidationError, MissingFieldError, InvalidTypeError, ProfileNotFoundError, CURRENT_SCHEMA_VERSION; print('All exports OK'); assert CURRENT_SCHEMA_VERSION == 1"`

Run: `cd /home/corye/Claude/Job-Radar && python -c "from job_radar.paths import get_backup_dir; d = get_backup_dir(); print(f'Backup dir: {d}'); assert d.exists()"`

Run: `cd /home/corye/Claude/Job-Radar && python -c "
from job_radar.profile_manager import validate_profile, ProfileValidationError, MissingFieldError
try:
    validate_profile({})
    print('FAIL: should have raised')
except MissingFieldError as e:
    print(f'OK: {e}')
try:
    validate_profile({'name': 'Test', 'target_titles': [], 'core_skills': ['Python']})
    print('FAIL: should have raised for empty titles')
except ProfileValidationError as e:
    print(f'OK: {e}')
print('Validation tests passed')
"`
  </verify>
  <done>
profile_manager.py exists with all 4 exception classes, validate_profile(), save_profile() with atomic write + backup + rotation, load_profile() with schema migration. paths.py has get_backup_dir(). All imports succeed and validation rejects invalid data with specific error types.
  </done>
</task>

</tasks>

<verification>
- `python -c "from job_radar.profile_manager import load_profile, save_profile, validate_profile"` succeeds
- `python -c "from job_radar.paths import get_backup_dir"` succeeds
- validate_profile rejects: empty dict, missing required fields, wrong types, out-of-range values
- validate_profile accepts: valid profile dict with required + optional fields
- save_profile creates backup before overwrite, rotates to keep max 10
- save_profile writes atomically (temp file + rename pattern)
- save_profile always sets schema_version to 1
- load_profile migrates schema_version 0 -> 1 and auto-saves
- load_profile rejects invalid JSON with clear error message
</verification>

<success_criteria>
1. profile_manager.py exports: load_profile, save_profile, validate_profile, 4 exception classes, CURRENT_SCHEMA_VERSION
2. Atomic write uses tempfile.mkstemp + os.fsync + Path.replace pattern (extracted from wizard.py)
3. Backup files created with microsecond-precision timestamps in get_backup_dir() path
4. Rotation keeps exactly 10 most recent backups
5. Schema version written as integer 1 on every save
6. All validation errors are subclasses of ProfileValidationError
</success_criteria>

<output>
After completion, create `.planning/phases/24-profile-infrastructure/24-01-SUMMARY.md`
</output>

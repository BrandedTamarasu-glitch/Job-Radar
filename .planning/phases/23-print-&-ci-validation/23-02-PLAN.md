---
phase: 23-print-ci-validation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - .github/workflows/accessibility.yml
  - lighthouserc.js
  - scripts/generate_ci_report.py
autonomous: false

must_haves:
  truths:
    - "GitHub Actions CI runs Lighthouse accessibility audit (5 runs, median score >=95) on every PR"
    - "CI runs axe-core checks for WCAG violations blocking merge on failures"
    - "Accessibility test reports upload as GitHub Actions artifacts for inspection"
    - "CI handles localStorage hydration timing with disableStorageReset and axe-core load delay"
    - "CI generates a realistic sample HTML report with jobs spanning all score tiers"
  artifacts:
    - path: ".github/workflows/accessibility.yml"
      provides: "GitHub Actions workflow running Lighthouse CI + axe-core on PRs"
      contains: "treosh/lighthouse-ci-action"
    - path: "lighthouserc.js"
      provides: "Lighthouse CI configuration with 5 runs, 0.95 threshold, filesystem upload"
      contains: "numberOfRuns: 5"
    - path: "scripts/generate_ci_report.py"
      provides: "Python script generating a realistic sample HTML report for CI testing"
      contains: "generate_report"
  key_links:
    - from: ".github/workflows/accessibility.yml"
      to: "lighthouserc.js"
      via: "configPath reference"
      pattern: "configPath.*lighthouserc"
    - from: ".github/workflows/accessibility.yml"
      to: "scripts/generate_ci_report.py"
      via: "python scripts/generate_ci_report.py step"
      pattern: "generate_ci_report"
    - from: "lighthouserc.js"
      to: "ci-report directory"
      via: "staticDistDir"
      pattern: "staticDistDir.*ci-report"
---

<objective>
Create a GitHub Actions accessibility CI workflow that runs Lighthouse (5 runs, median score >=0.95) and axe-core (WCAG 2.1 AA) on every pull request, generating a realistic sample HTML report for testing and uploading results as artifacts.

Purpose: Automated enforcement ensures accessibility regressions are caught before merge, protecting the WCAG 2.1 AA compliance established in Phase 18.
Output: New workflow file, Lighthouse config, and CI report generation script
</objective>

<execution_context>
@/Users/coryebert/.claude/get-shit-done/workflows/execute-plan.md
@/Users/coryebert/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/23-print-&-ci-validation/23-RESEARCH.md
@.github/workflows/release.yml (existing workflow pattern for Python setup, dependencies)
@pyproject.toml (project installation: pip install -e .[dev])
@tests/test_report.py (lines 11-137: sample fixtures showing JobResult construction and generate_report usage)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CI report generation script, Lighthouse config, and accessibility workflow</name>
  <files>scripts/generate_ci_report.py, lighthouserc.js, .github/workflows/accessibility.yml</files>
  <action>
**File 1: `scripts/generate_ci_report.py`**

Create a Python script that generates a realistic HTML report in `./ci-report/` for CI accessibility testing. The script must:

1. Import `generate_report` from `job_radar.report` and `JobResult` from `job_radar.sources`
2. Create a sample profile dict matching the test fixture pattern (name, target_titles, core_skills, level, years_experience, location, arrangement)
3. Create scored_results with at least 3 jobs covering all tiers:
   - One hero tier job (score >= 4.0, "Strong match")
   - One recommended tier job (score 3.5-3.9, "Good match")
   - One review tier job (score 2.8-3.4, "Below threshold")
4. Call `generate_report()` with output_dir="./ci-report"
5. Find the generated HTML file (it has a timestamp in the name: `jobs_YYYY-MM-DD_HH-MM.html`)
6. Rename it to `index.html` in the same directory (Lighthouse CI staticDistDir needs a predictable filename)
7. Print the output path for CI logging

Use the exact same field structure as test_report.py fixtures (including `parse_confidence="high"` on JobResult). Include `manual_urls=[]` and `sources_searched=["CI Test"]`.

**File 2: `lighthouserc.js`** (project root)

```javascript
module.exports = {
  ci: {
    collect: {
      numberOfRuns: 5,
      staticDistDir: './ci-report',
      settings: {
        chromeFlags: '--no-sandbox --disable-gpu',
        disableStorageReset: true
      }
    },
    assert: {
      assertions: {
        'categories:accessibility': ['error', { minScore: 0.95 }]
      }
    },
    upload: {
      target: 'filesystem',
      outputDir: './lhci-results'
    }
  }
};
```

**File 3: `.github/workflows/accessibility.yml`**

Create a workflow that:
1. Triggers on `pull_request` to `main` branch
2. Runs on `ubuntu-latest`
3. Sets up Python 3.10 (actions/setup-python@v5) and Node.js 20 (actions/setup-node@v4)
4. Installs project: `pip install -e .` (no dev deps needed, just core for report generation)
5. Runs `python scripts/generate_ci_report.py` to produce `ci-report/index.html`
6. Runs Lighthouse CI via `treosh/lighthouse-ci-action@v12` with `configPath: ./lighthouserc.js` and `uploadArtifacts: true`
7. Installs `@axe-core/cli` globally via npm
8. Starts a background HTTP server: `python3 -m http.server 8080 --directory ./ci-report &`
9. Waits 2 seconds for server startup
10. Runs axe-core: `axe http://localhost:8080/index.html --tags wcag2a,wcag2aa,wcag21a,wcag21aa --exit --save axe-results.json --dir ./axe-results`
11. Uploads axe results as artifact (actions/upload-artifact@v4) with `if: always()` so results upload even on failure

Match the style of the existing `release.yml` workflow (step naming, indentation).

Important notes:
- The `--exit` flag on axe-core is critical: without it, violations return exit code 0 (CI would never fail)
- `disableStorageReset: true` in Lighthouse config handles the localStorage hydration timing concern from STATE.md
- `staticDistDir` makes Lighthouse CI host the files itself, no separate server needed for Lighthouse (only axe-core needs the python server)
- Use `--load-delay 2000` with axe-core CLI to allow DOMContentLoaded scripts to complete before auditing
  </action>
  <verify>
Verify all 3 files exist and have correct structure:
- `test -f scripts/generate_ci_report.py && echo "CI script exists"`
- `test -f lighthouserc.js && echo "Lighthouse config exists"`
- `test -f .github/workflows/accessibility.yml && echo "Workflow exists"`
- `python -c "import ast; ast.parse(open('scripts/generate_ci_report.py').read()); print('Python syntax OK')"`
- `node -e "require('./lighthouserc.js'); console.log('JS config OK')"`
- `grep 'numberOfRuns: 5' lighthouserc.js` confirms 5 runs configured
- `grep 'minScore: 0.95' lighthouserc.js` confirms 95% threshold
- `grep '\-\-exit' .github/workflows/accessibility.yml` confirms axe-core exit flag
- `grep 'treosh/lighthouse-ci-action' .github/workflows/accessibility.yml` confirms Lighthouse action
  </verify>
  <done>
Three files created: (1) scripts/generate_ci_report.py generates a realistic multi-tier HTML report, (2) lighthouserc.js configures 5-run Lighthouse with 0.95 accessibility threshold, (3) .github/workflows/accessibility.yml runs both tools on PRs with artifact upload.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete accessibility CI pipeline with:
1. `scripts/generate_ci_report.py` - Generates sample report with 3 tiers of job results
2. `lighthouserc.js` - Lighthouse CI config (5 runs, median >= 0.95 accessibility)
3. `.github/workflows/accessibility.yml` - GitHub Actions workflow running Lighthouse + axe-core on PRs

The CI report generation script can be tested locally.
  </what-built>
  <how-to-verify>
1. Run the CI report generation script locally:
   ```
   mkdir -p ci-report
   python scripts/generate_ci_report.py
   ```
   Verify `ci-report/index.html` is generated and opens correctly in browser.

2. Review the workflow file `.github/workflows/accessibility.yml`:
   - Confirm it triggers on pull_request to main
   - Confirm Lighthouse CI step references lighthouserc.js
   - Confirm axe-core step uses --exit flag
   - Confirm artifacts upload step uses `if: always()`

3. Review `lighthouserc.js`:
   - Confirm numberOfRuns: 5
   - Confirm minScore: 0.95
   - Confirm disableStorageReset: true

4. (Optional) To test the full CI locally, you can push a branch and open a PR to see the workflow execute.
  </how-to-verify>
  <resume-signal>Type "approved" if the CI files look correct, or describe any issues to fix</resume-signal>
</task>

</tasks>

<verification>
1. `python scripts/generate_ci_report.py` runs without errors and produces ci-report/index.html
2. `node -e "require('./lighthouserc.js')"` parses without errors
3. The accessibility.yml workflow file is valid YAML (GitHub will validate on push)
4. `grep -c 'treosh/lighthouse-ci-action' .github/workflows/accessibility.yml` returns 1
5. `grep -c '@axe-core/cli' .github/workflows/accessibility.yml` returns 1
6. `grep -c 'numberOfRuns: 5' lighthouserc.js` returns 1
</verification>

<success_criteria>
- accessibility.yml workflow triggers on PRs to main
- Lighthouse CI configured for 5 runs with median accessibility score >= 0.95
- axe-core runs with --exit flag ensuring CI fails on WCAG violations
- Sample report generation script produces a multi-tier HTML report
- Lighthouse results and axe results uploaded as GitHub Actions artifacts
- localStorage hydration timing handled via disableStorageReset
- Human verifies the generated report opens correctly and CI files look correct
</success_criteria>

<output>
After completion, create `.planning/phases/23-print-&-ci-validation/23-02-SUMMARY.md`
</output>

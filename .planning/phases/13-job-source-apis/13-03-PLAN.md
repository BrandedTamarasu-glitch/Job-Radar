---
phase: 13-job-source-apis
plan: 03
type: execute
wave: 3
depends_on: ["13-02"]
files_modified:
  - tests/test_sources_api.py
  - tests/test_deduplication.py
autonomous: true

must_haves:
  truths:
    - "Tests verify Adzuna mapper produces correct JobResult from valid API response"
    - "Tests verify Authentic Jobs mapper produces correct JobResult from valid API response"
    - "Tests verify invalid jobs (missing title/company/url) return None from mappers"
    - "Tests verify HTML stripping and entity decoding in strip_html_and_normalize"
    - "Tests verify location parsing for US states, Remote, and international locations"
    - "Tests verify cross-source deduplication removes fuzzy duplicates"
    - "Tests verify exact duplicates are caught by fast path"
    - "Tests verify deduplication keeps first occurrence (scraper priority)"
    - "Tests verify build_search_queries includes adzuna and authentic_jobs sources"
    - "Tests verify fetch functions return empty list on missing credentials"
    - "All tests pass with pytest"
  artifacts:
    - path: "tests/test_sources_api.py"
      provides: "Tests for API fetcher functions, mapper functions, text utilities, pipeline integration"
      min_lines: 100
    - path: "tests/test_deduplication.py"
      provides: "Tests for cross-source fuzzy deduplication"
      min_lines: 60
  key_links:
    - from: "tests/test_sources_api.py"
      to: "job_radar/sources.py"
      via: "imports"
      pattern: "from job_radar.sources import"
    - from: "tests/test_deduplication.py"
      to: "job_radar/deduplication.py"
      via: "imports"
      pattern: "from job_radar.deduplication import"
---

<objective>
Create comprehensive test coverage for all Phase 13 code: API mapper functions, text utilities (HTML stripping, location parsing), cross-source deduplication, fetch function error handling, and pipeline integration.

Purpose: Verify all CONTEXT.md requirements are met — strict validation, HTML cleanup, location normalization, fuzzy deduplication, error handling patterns. Tests prevent regressions as Phase 14-15 build on this foundation.
Output: Two test files covering all Phase 13 functionality.
</objective>

<execution_context>
@/Users/coryebert/.claude/get-shit-done/workflows/execute-plan.md
@/Users/coryebert/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-job-source-apis/13-CONTEXT.md
@.planning/phases/13-job-source-apis/13-RESEARCH.md
@.planning/phases/13-job-source-apis/13-01-SUMMARY.md
@.planning/phases/13-job-source-apis/13-02-SUMMARY.md
@job_radar/sources.py
@job_radar/deduplication.py
@tests/test_api_config.py
@tests/test_rate_limits.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create API source tests (mappers, text utils, fetcher error handling, pipeline)</name>
  <files>tests/test_sources_api.py</files>
  <action>
  Create tests/test_sources_api.py with comprehensive tests for Phase 13 API functionality.

  Follow existing test conventions from tests/test_api_config.py and tests/test_rate_limits.py:
  - Use pytest fixtures (monkeypatch, tmp_path)
  - Use caplog for log message verification
  - Use parametrize for multiple test cases
  - Module docstring at top

  **Test categories:**

  **1. Adzuna mapper tests (map_adzuna_to_job_result):**

  ```python
  def test_map_adzuna_valid_job():
      """Valid Adzuna item maps to JobResult with all fields."""
      # Full valid item with title, company, url, salary, location, description
      # Assert: title, company, location normalized, salary fields populated, HTML stripped from description

  def test_map_adzuna_missing_title_returns_none():
      """Item with empty title returns None (strict validation)."""

  def test_map_adzuna_missing_company_returns_none():
      """Item with missing company returns None."""

  def test_map_adzuna_missing_url_returns_none():
      """Item with empty redirect_url returns None."""

  def test_map_adzuna_salary_formatting():
      """Salary formats correctly: range, min-only, not-specified."""
      # Parametrize: (salary_min, salary_max, expected_salary_str)
      # Cases: (80000, 120000, "$80,000 - $120,000"), (80000, None, "$80,000+"), (None, None, "Not specified")

  def test_map_adzuna_html_description_cleaned():
      """HTML tags and entities stripped from description."""
      # Input: "<p>Great &amp; exciting <b>role</b></p>"
      # Expected: "Great & exciting role"

  def test_map_adzuna_location_normalized():
      """Location normalized to City, State format."""
      # Input: {"display_name": "San Francisco, California, United States"}
      # Expected: "San Francisco, CA"
  ```

  **2. Authentic Jobs mapper tests (map_authenticjobs_to_job_result):**

  ```python
  def test_map_authenticjobs_valid_job():
      """Valid Authentic Jobs item maps to JobResult."""

  def test_map_authenticjobs_missing_required_fields_returns_none():
      """Item missing title/company/url returns None."""
  ```

  **3. Text utility tests:**

  ```python
  def test_strip_html_and_normalize_basic():
      """Strips tags and normalizes whitespace."""

  def test_strip_html_and_normalize_entities():
      """Decodes HTML entities: &amp; -> &, &#39; -> ', &nbsp; -> space."""

  def test_strip_html_and_normalize_empty():
      """Empty string returns empty string."""

  def test_strip_html_and_normalize_nested_tags():
      """Handles nested HTML tags correctly."""

  @pytest.mark.parametrize("input_loc,expected", [
      ("San Francisco, CA", "San Francisco, CA"),
      ("San Francisco, California, United States", "San Francisco, CA"),
      ("Remote", "Remote"),
      ("remote work available", "Remote"),
      ("New York, NY 10001", "New York, NY"),
      ("London, UK", "London, UK"),
      ("", "Unknown"),
      ("Austin, Texas", "Austin, TX"),
  ])
  def test_parse_location_to_city_state(input_loc, expected):
      """Location parsing handles various formats."""
  ```

  **4. Fetch function error handling tests:**

  ```python
  def test_fetch_adzuna_missing_credentials(monkeypatch):
      """Returns empty list when API credentials missing."""
      # Monkeypatch get_api_key to return None
      # Assert: fetch_adzuna returns []

  def test_fetch_adzuna_rate_limited(monkeypatch):
      """Returns empty list when rate limited."""
      # Monkeypatch check_rate_limit to return False
      # Assert: fetch_adzuna returns []

  def test_fetch_authenticjobs_missing_credentials(monkeypatch):
      """Returns empty list when API key missing."""
  ```

  **5. Pipeline integration tests:**

  ```python
  def test_build_search_queries_includes_api_sources():
      """build_search_queries includes adzuna and authentic_jobs sources."""
      profile = {"name": "T", "target_titles": ["Dev"], "core_skills": ["python"], "target_market": "NYC"}
      queries = build_search_queries(profile)
      sources = {q["source"] for q in queries}
      assert "adzuna" in sources
      assert "authentic_jobs" in sources

  def test_build_search_queries_api_includes_location():
      """API queries include location from profile."""
      profile = {"name": "T", "target_titles": ["Dev"], "core_skills": ["python"], "target_market": "San Francisco, CA"}
      queries = build_search_queries(profile)
      api_queries = [q for q in queries if q["source"] in ("adzuna", "authentic_jobs")]
      for q in api_queries:
          assert q.get("location") == "San Francisco, CA"
  ```

  Use monkeypatch to mock external dependencies (get_api_key, check_rate_limit, fetch_with_retry) in fetch function tests. Do NOT make real API calls.
  </action>
  <verify>
  `python -m pytest tests/test_sources_api.py -v` — All tests pass
  `python -m pytest tests/ -x -q` — Full suite still passes
  </verify>
  <done>
  Comprehensive API source tests created: mapper validation (valid + invalid jobs), salary formatting, HTML stripping, location parsing (parametrized), credential/rate-limit error handling, pipeline integration (queries include API sources). All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create deduplication tests</name>
  <files>tests/test_deduplication.py</files>
  <action>
  Create tests/test_deduplication.py with comprehensive tests for cross-source fuzzy deduplication.

  Follow existing test conventions. Import from job_radar.deduplication and job_radar.sources (for JobResult).

  Helper function to create test JobResult:
  ```python
  def _make_job(title="Engineer", company="Acme", location="Remote", source="Dice", **kwargs):
      return JobResult(
          title=title, company=company, location=location,
          arrangement="remote", salary="Not listed", date_posted="today",
          description="desc", url=f"http://{source.lower()}.com/job",
          source=source, **kwargs
      )
  ```

  **Test cases:**

  ```python
  def test_empty_input():
      """Empty list returns empty list."""
      assert deduplicate_cross_source([]) == []

  def test_single_job_returned():
      """Single job passes through unchanged."""

  def test_exact_duplicates_removed():
      """Exact same title+company+location from different sources — keeps first."""
      j1 = _make_job(source="Dice")
      j2 = _make_job(source="adzuna")
      result = deduplicate_cross_source([j1, j2])
      assert len(result) == 1
      assert result[0].source == "Dice"  # First occurrence kept

  def test_fuzzy_title_duplicates_removed():
      """'Senior Software Engineer' vs 'Software Engineer, Senior' detected as duplicate."""
      j1 = _make_job(title="Senior Software Engineer", source="Dice")
      j2 = _make_job(title="Software Engineer, Senior", source="adzuna")
      result = deduplicate_cross_source([j1, j2])
      assert len(result) == 1

  def test_fuzzy_company_variation():
      """'Google Inc' vs 'Google Inc.' detected as duplicate."""
      j1 = _make_job(company="Google Inc", source="Dice")
      j2 = _make_job(company="Google Inc.", source="adzuna")
      result = deduplicate_cross_source([j1, j2])
      assert len(result) == 1

  def test_different_jobs_not_deduplicated():
      """Different title+company combinations are kept."""
      j1 = _make_job(title="Frontend Dev", company="Google")
      j2 = _make_job(title="Backend Dev", company="Meta")
      result = deduplicate_cross_source([j1, j2])
      assert len(result) == 2

  def test_same_title_different_company_not_deduplicated():
      """Same title at different companies are kept."""
      j1 = _make_job(title="Software Engineer", company="Google")
      j2 = _make_job(title="Software Engineer", company="Meta")
      result = deduplicate_cross_source([j1, j2])
      assert len(result) == 2

  def test_preserves_order():
      """First occurrence kept — scraper results before API results."""
      j1 = _make_job(title="Dev", company="Co", source="Dice")
      j2 = _make_job(title="Dev", company="Co", source="adzuna")
      j3 = _make_job(title="Other", company="Other", source="HN Hiring")
      result = deduplicate_cross_source([j1, j2, j3])
      assert len(result) == 2
      assert result[0].source == "Dice"

  def test_location_similarity_threshold():
      """Different locations prevent deduplication even with same title+company."""
      j1 = _make_job(location="San Francisco, CA")
      j2 = _make_job(location="New York, NY")
      result = deduplicate_cross_source([j1, j2])
      assert len(result) == 2  # Different locations = different jobs

  def test_dedup_logs_stats(caplog):
      """Deduplication logs stats when duplicates found."""
      import logging
      caplog.set_level(logging.DEBUG)
      j1 = _make_job(source="Dice")
      j2 = _make_job(source="adzuna")
      deduplicate_cross_source([j1, j2])
      assert any("Deduplication" in r.message or "duplicate" in r.message.lower() for r in caplog.records)

  def test_empty_company_handled():
      """Jobs with empty company name don't crash."""
      j1 = _make_job(company="", source="Dice")
      j2 = _make_job(company="Acme", source="adzuna")
      result = deduplicate_cross_source([j1, j2])
      assert len(result) == 2  # Different companies, both kept
  ```
  </action>
  <verify>
  `python -m pytest tests/test_deduplication.py -v` — All tests pass
  `python -m pytest tests/ -x -q` — Full suite passes (all existing + new tests)
  </verify>
  <done>
  Deduplication tests verify: empty input, single job, exact duplicates, fuzzy title/company matching, different jobs preserved, same title at different companies preserved, scraper priority (first occurrence), location threshold, stats logging, edge cases (empty company). All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_sources_api.py -v` — All API source tests pass
2. `python -m pytest tests/test_deduplication.py -v` — All deduplication tests pass
3. `python -m pytest tests/ -x -q` — Full test suite passes (existing + new)
4. `python -m pytest tests/ --tb=short -q | tail -5` — No failures, no errors
</verification>

<success_criteria>
- Adzuna mapper tested: valid mapping, missing required fields, salary formatting, HTML cleanup, location normalization
- Authentic Jobs mapper tested: valid mapping, missing required fields
- Text utilities tested: strip_html_and_normalize (tags, entities, empty, nested), parse_location_to_city_state (parametrized with 8+ cases)
- Fetcher error handling tested: missing credentials, rate limiting
- Pipeline tested: build_search_queries includes API sources with locations
- Deduplication tested: exact dupes, fuzzy title/company, different jobs preserved, scraper priority, location threshold, edge cases
- All tests pass including existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/13-job-source-apis/13-03-SUMMARY.md`
</output>

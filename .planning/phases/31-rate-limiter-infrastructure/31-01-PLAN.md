---
phase: 31-rate-limiter-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - job_radar/rate_limits.py
  - tests/test_rate_limits.py
autonomous: true

must_haves:
  truths:
    - "Application exits cleanly without 'database is locked' errors after running searches with API sources"
    - "Sources sharing the same backend API (e.g., multiple sources using JSearch) use a single shared rate limiter instance"
    - "SQLite connections are closed when application exits via atexit handler"
  artifacts:
    - path: "job_radar/rate_limits.py"
      provides: "atexit cleanup handler and backend API mapping for shared limiters"
      contains: "atexit.register"
      exports: ["get_rate_limiter", "check_rate_limit", "BACKEND_API_MAP"]
    - path: "tests/test_rate_limits.py"
      provides: "Tests for atexit cleanup and shared limiter behavior"
      min_lines: 100
  key_links:
    - from: "job_radar/rate_limits.py"
      to: "atexit module"
      via: "atexit.register(cleanup_connections)"
      pattern: "atexit\\.register"
    - from: "job_radar/rate_limits.py"
      to: "_connections dict"
      via: "shared limiter lookup uses BACKEND_API_MAP"
      pattern: "BACKEND_API_MAP\\[source\\]"
---

<objective>
Fix rate limiter SQLite connection leaks and establish shared backend API management.

Purpose: Prevent "database is locked" errors on app exit and prepare infrastructure for multiple sources sharing the same backend API (e.g., JSearch will power LinkedIn, Indeed, Glassdoor sources).

Output: Clean shutdown with atexit handler, shared rate limiter instances for sources using the same backend API.
</objective>

<execution_context>
@/home/corye/.claude/get-shit-done/workflows/execute-plan.md
@/home/corye/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Current implementation
@job_radar/rate_limits.py
@tests/test_rate_limits.py
</context>

<tasks>

<task type="auto">
  <name>Add atexit cleanup handler for SQLite connections</name>
  <files>job_radar/rate_limits.py</files>
  <action>
Add atexit handler to close all SQLite connections in _connections dict on application exit.

Implementation:
1. Import atexit at top of module
2. Create _cleanup_connections() function that:
   - Iterates over _connections.values()
   - Calls conn.close() on each connection
   - Wraps in try/except to prevent cleanup failures from crashing exit
   - Logs debug message: "Closed {len(_connections)} rate limiter database connections"
3. Register cleanup with atexit.register(_cleanup_connections) at module level (after function definition)

Why atexit (not __del__ or context managers):
- CLI apps exit via sys.exit() or natural termination - atexit handlers run in both cases
- Context managers require wrapping entire application - not practical for CLI tools
- __del__ is unreliable (depends on garbage collection timing)

Note: Cleanup runs automatically on normal exit, Ctrl+C (KeyboardInterrupt), and sys.exit(). Does NOT run on SIGKILL or os._exit().
  </action>
  <verify>
Run test search with API sources, exit, check no "database is locked" errors:
```bash
python -m pytest tests/test_rate_limits.py -v -k cleanup
python -m job_radar --profile tests/fixtures/sample_profile.json --dry-run
# Exit cleanly - no SQLite errors
```
  </verify>
  <done>
Application exits without "database is locked" errors. atexit handler closes all SQLite connections in _connections dict. Tests verify cleanup behavior.
  </done>
</task>

<task type="auto">
  <name>Implement shared rate limiters for sources using same backend API</name>
  <files>job_radar/rate_limits.py, tests/test_rate_limits.py</files>
  <action>
Create BACKEND_API_MAP to map source names to shared backend API identifiers, then modify get_rate_limiter to use backend API name for limiter cache key instead of source name.

Implementation:

1. Add BACKEND_API_MAP dict after RATE_LIMITS (before _limiters cache):
```python
# Map sources to backend APIs - sources sharing the same backend API share rate limiters
BACKEND_API_MAP = {
    "adzuna": "adzuna",
    "authentic_jobs": "authentic_jobs",
    # Future sources will map multiple sources to same backend:
    # "linkedin": "jsearch",
    # "indeed": "jsearch",
    # "glassdoor": "jsearch",
}
```

2. Update get_rate_limiter(source) to:
   - Look up backend_api = BACKEND_API_MAP.get(source, source) (fallback to source name if not in map)
   - Use backend_api as cache key for _limiters dict instead of source
   - Use backend_api for rate config lookup: rates = RATE_LIMITS.get(backend_api, [Rate(60, Duration.MINUTE)])
   - Use backend_api for database filename: db_path = rate_limits_dir / f"{backend_api}.db"
   - Update _connections key to use backend_api
   - Update log message: "Initialized rate limiter for {source} (backend: {backend_api}) with {len(rates)} rate(s)"

3. Update check_rate_limit(source) to:
   - Look up backend_api = BACKEND_API_MAP.get(source, source)
   - Get rates from RATE_LIMITS using backend_api
   - Keep warning message using source name (user-facing): "Skipped {source}: rate limited, retry after {reset_str}"

4. Add tests in test_rate_limits.py:
   - test_shared_backend_limiters() - verify multiple sources mapped to same backend share limiter cache
   - test_backend_map_fallback() - verify unmapped sources use source name as backend
   - test_cleanup_closes_all_connections() - verify atexit handler closes connections

Why this design:
- Future Phase 32 will add JSearch API with 3 sources (linkedin, indeed, glassdoor) all using same backend API
- Shared limiters prevent hitting rate limits 3x faster when user searches all three
- Fallback to source name preserves backward compatibility for unmapped sources
  </action>
  <verify>
Run tests verifying shared limiter behavior:
```bash
python -m pytest tests/test_rate_limits.py::test_shared_backend_limiters -v
python -m pytest tests/test_rate_limits.py::test_backend_map_fallback -v
python -m pytest tests/test_rate_limits.py::test_cleanup_closes_all_connections -v
python -m pytest tests/test_rate_limits.py -v
```
  </verify>
  <done>
Sources mapped in BACKEND_API_MAP share rate limiter instances (verified by test). Unmapped sources fall back to source name. Database files use backend API name. Tests pass. get_rate_limiter logs show backend API name.
  </done>
</task>

</tasks>

<verification>
1. Run full test suite - no regressions: `python -m pytest tests/ -v`
2. Verify atexit cleanup in manual test: Run CLI with --dry-run, exit, check no SQLite errors
3. Check BACKEND_API_MAP structure matches Phase 32 requirements (jsearch will map 3 sources)
4. Verify _connections dict closes all connections on exit
</verification>

<success_criteria>
1. Application exits cleanly without "database is locked" errors (INFRA-01)
2. Sources sharing backend API use single shared rate limiter instance (INFRA-02 foundation)
3. All tests pass including new cleanup and shared limiter tests
4. atexit handler registered and functional
</success_criteria>

<output>
After completion, create `.planning/phases/31-rate-limiter-infrastructure/31-01-SUMMARY.md`
</output>

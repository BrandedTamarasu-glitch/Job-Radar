---
phase: 29-profile-setup-search-controls
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - job_radar/gui/search_controls.py
  - job_radar/gui/worker_thread.py
  - job_radar/sources.py
autonomous: true

must_haves:
  truths:
    - "User can set date range (from/to) for job postings via date picker widgets"
    - "User can set minimum score threshold via numeric entry"
    - "User can toggle new-only mode via switch widget"
    - "Default values match CLI defaults (no date filter, min score from config)"
    - "Search execution runs real sources.fetch_all() in worker thread without freezing GUI"
    - "Progress shows source name + job count as each source completes"
    - "Search completion shows total jobs found with Open Report button"
    - "Partial source failures are handled silently — report opens with whatever succeeded"
  artifacts:
    - path: "job_radar/gui/search_controls.py"
      provides: "Search configuration widget with date pickers, min score, new-only toggle"
      exports: ["SearchControls"]
    - path: "job_radar/gui/worker_thread.py"
      provides: "Real SearchWorker replacing MockSearchWorker, plus existing mock workers"
      exports: ["SearchWorker", "create_search_worker", "MockSearchWorker", "create_mock_worker"]
    - path: "job_radar/sources.py"
      provides: "Extended on_source_progress callback with per-source job count"
      contains: "on_source_progress(display_name, sources_done, total_sources, \"complete\", source_job_count)"
  key_links:
    - from: "job_radar/gui/worker_thread.py"
      to: "job_radar/sources.py"
      via: "fetch_all() with on_source_progress callback including job_count"
      pattern: "from job_radar\\.sources import fetch_all"
    - from: "job_radar/gui/worker_thread.py"
      to: "job_radar/scoring.py"
      via: "score_job() for scoring fetched results"
      pattern: "from job_radar\\.scoring import score_job"
    - from: "job_radar/gui/worker_thread.py"
      to: "job_radar/report.py"
      via: "generate_report() for HTML report creation"
      pattern: "from job_radar\\.report import generate_report"
    - from: "job_radar/gui/search_controls.py"
      to: "job_radar/config.py"
      via: "load_config() for default values"
      pattern: "from job_radar\\.config import load_config"
---

<objective>
Create the search controls widget and real search worker that replaces Phase 28's mock, enabling actual job search execution from the GUI.

Purpose: Deliver search configuration (SRCH-01 through SRCH-05) and search execution with progress feedback (PROG-01, PROG-02). The search controls widget is standalone; the worker thread module extends the existing worker_thread.py with a real SearchWorker that orchestrates the full pipeline (fetch -> score -> filter -> report).

Output: New search_controls.py widget + updated worker_thread.py with real SearchWorker class + minor sources.py enhancement for per-source job counts.
</objective>

<execution_context>
@/home/corye/.claude/get-shit-done/workflows/execute-plan.md
@/home/corye/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-profile-setup-search-controls/29-CONTEXT.md
@.planning/phases/29-profile-setup-search-controls/29-RESEARCH.md

# Existing code — critical for understanding search pipeline
@job_radar/gui/worker_thread.py
@job_radar/gui/main_window.py
@job_radar/sources.py
@job_radar/search.py
@job_radar/scoring.py
@job_radar/report.py
@job_radar/tracker.py
@job_radar/config.py
@job_radar/paths.py
@job_radar/browser.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SearchControls widget with date pickers, min score, and new-only toggle</name>
  <files>job_radar/gui/search_controls.py</files>
  <action>
Create a CustomTkinter widget class `SearchControls(ctk.CTkFrame)` that provides search configuration controls.

**Constructor parameters:**
- `parent` — parent widget
- Standard CTkFrame kwargs

**Layout (at Claude's discretion per CONTEXT.md, but must include all required controls):**
- Date range section with "Apply date filter" checkbox (unchecked by default per research recommendation) that enables/disables two date entry fields. When unchecked, date fields are disabled and search runs without date filter (matching CLI default behavior). When checked, the date fields become active.
- For date range: Use two CTkEntry fields with placeholder text "YYYY-MM-DD" format. CTkDatePicker is recommended in research but may not be easily installable — use simple CTkEntry fields with date format validation as fallback. If CTkDatePicker is available, use it; otherwise fall back to manual entry with validation. Try to import CTkDatePicker at module level with ImportError fallback.
- Minimum score: CTkEntry with default value loaded from config.json (load_config()). Validate 0.0-5.0 range on FocusOut. Default to 2.8 if no config exists.
- New only: CTkSwitch (toggle switch per locked decision) with default from config.json. Default to False if no config exists.

**Public API:**
- `get_config() -> dict` — returns {"from_date": str|None, "to_date": str|None, "min_score": float, "new_only": bool}. Returns None for dates when checkbox is unchecked.
- `validate() -> tuple[bool, str]` — validates all controls, returns (is_valid, error_message). Checks date format if enabled, score range.
- `set_defaults(config: dict)` — set control values from a config dict

**Validation:**
- Date format: YYYY-MM-DD regex check when date filter is enabled
- Min score: float, 0.0-5.0 range (reuse ScoreValidator logic from wizard.py, same pattern as ProfileForm)
- FocusOut validation on min_score entry with inline error label

**Defaults per locked decisions:**
- No date filter by default (checkbox unchecked, matching CLI behavior of no --from/--to)
- Min score from config.json > 2.8 fallback
- New only from config.json > False fallback

Follow codebase conventions: module docstring, type hints, private methods with underscore prefix.
  </action>
  <verify>
Run: `python -c "from job_radar.gui.search_controls import SearchControls; print('SearchControls imported successfully')"`
Run: `python -m py_compile job_radar/gui/search_controls.py && echo 'Syntax OK'`
Grep to confirm key integrations:
- `grep -c "CTkSwitch\|CTkEntry" job_radar/gui/search_controls.py` should be >= 2
- `grep -c "get_config\|validate" job_radar/gui/search_controls.py` should be >= 2
  </verify>
  <done>
SearchControls widget imports cleanly, provides date range (with enable/disable checkbox), min score entry with validation, new-only toggle switch, get_config() returning search parameters, and defaults loaded from config.json.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add per-source job counts to sources.py callback and create real SearchWorker</name>
  <files>job_radar/sources.py, job_radar/gui/worker_thread.py</files>
  <action>
**Part A: Extend on_source_progress callback in sources.py to include per-source job count**

In `sources.py`, modify the `_run_queries_parallel` inner function (inside `fetch_all`) to track per-source result counts and pass them in the `on_source_progress` callback when a source completes.

Specific changes to `_run_queries_parallel`:
1. Add a `source_job_counts: dict[str, int]` dict initialized to 0 for each source (same pattern as `source_completed` dict at line ~1218).
2. In the results processing loop (lines ~1262-1268), when results are added to `phase_results`, also increment `source_job_counts[source]` by the number of deduplicated results added for that query. Specifically, count how many results pass the `seen` dedup check for each future's query source.
3. At the source completion callback (line ~1279-1281), pass the job count as a 5th argument:
   ```python
   on_source_progress(display_name, sources_done, total_sources, "complete", source_job_counts.get(source, 0))
   ```
4. For the "started" callback (line ~1255), pass 0 as the 5th argument for consistency:
   ```python
   on_source_progress(display_name, sources_started, total_sources, "started", 0)
   ```

This is backward-compatible: any existing callback that accepts `*args` or only positional args will still work. The `on_progress` callback is NOT changed — only `on_source_progress` gets the extra parameter.

Update the `fetch_all` docstring to document the new 5th parameter:
```
on_source_progress: Optional callback(source_name, count, total, status, job_count)
                   called when a source starts ('started') or finishes ('complete').
                   job_count is the number of deduplicated results from that source (0 for 'started').
```

**Part B: Add SearchWorker to worker_thread.py with per-source job count in queue messages**

Add a `SearchWorker` class to the existing worker_thread.py module that executes the real search pipeline (fetch -> filter -> score -> track -> report), replacing the MockSearchWorker for production use. Keep MockSearchWorker intact for testing.

**SearchWorker class:**
- `__init__(self, result_queue: queue.Queue, stop_event: threading.Event, profile: dict, search_config: dict)` where search_config comes from SearchControls.get_config()
- `run(self)` method that executes the full pipeline:

  1. Load API credentials: `from job_radar.api_config import load_api_credentials; load_api_credentials()`
  2. Call `fetch_all(profile, on_source_progress=callback)` from sources.py
     - The on_source_progress callback receives 5 args: `(source_name, current, total, status, job_count)` per Part A above.
     - On "started": `self._queue.put(("source_started", source_name, current, total))`
     - On "complete": `self._queue.put(("source_complete", source_name, current, total, job_count))` — includes per-source job count per locked decision
     - Check stop_event between operations for cancellation
  3. Date filter: If search_config has from_date and to_date (not None), apply filter_by_date() from search.py
  4. Score all results: `score_job(result, profile)` from scoring.py for each result
     - Filter out dealbreaker matches (score.get("dealbreaker"))
     - Sort by score descending
  5. Track seen/new: `mark_seen(scored)` from tracker.py
  6. Apply filters: new_only filter, min_score filter from search_config
  7. Generate report: Call `generate_report()` from report.py with the same arguments pattern as search.py main()
     - Also call `generate_manual_urls(profile)` from sources.py
     - Also call `get_stats()` from tracker.py
  8. Send completion: `self._queue.put(("search_complete", len(scored), str(report_path)))` with job count and report path

  Error handling:
  - Wrap entire pipeline in try/except
  - On exception: `self._queue.put(("error", str(e)))`
  - Per locked decision: partial source failures are handled silently by fetch_all itself (it logs errors and continues). Do NOT add extra error handling around individual sources.
  - On cancellation (stop_event.is_set()): `self._queue.put(("cancelled",))`

- `cancel(self)` method: `self._stop_event.set()`

**Queue message format (extending Phase 28 protocol):**
- `("source_started", source_name: str, current: int, total: int)` — source fetching began
- `("source_complete", source_name: str, current: int, total: int, job_count: int)` — source fetching done, includes per-source job count
- `("search_complete", job_count: int, report_path: str)` — full pipeline done
- `("cancelled",)` — search was cancelled
- `("error", message: str)` — pipeline error

Note: The `source_complete` message now includes `job_count` as a 5th element (the number of deduplicated results found by that specific source). This enables Plan 03 to display "Dice: 12 jobs found" per the locked decision.

**Factory function:**
Add `create_search_worker(result_queue, profile, search_config)` that creates SearchWorker + thread (same pattern as create_mock_worker). Returns (worker, thread).

**Keep existing code:**
- MockSearchWorker, MockErrorWorker, create_mock_worker, create_mock_error_worker — all remain unchanged for testing
- Existing module docstring updated to reflect both mock and real workers

**Imports to add at top of file:**
```python
from job_radar.sources import fetch_all, generate_manual_urls, build_search_queries
from job_radar.scoring import score_job
from job_radar.report import generate_report
from job_radar.tracker import mark_seen, get_stats
from job_radar.search import filter_by_date
```
Use lazy imports inside run() method instead of module-level to avoid circular imports and keep the module importable even if some dependencies aren't available (e.g., during testing). This matches the codebase pattern in search.py where imports happen inside functions.

Follow codebase conventions: docstrings for class and methods, type hints, private underscore methods.
  </action>
  <verify>
Run: `python -c "from job_radar.gui.worker_thread import SearchWorker, create_search_worker; print('SearchWorker imported successfully')"`
Run: `python -c "from job_radar.gui.worker_thread import MockSearchWorker, create_mock_worker; print('Mock workers still work')"`
Run: `python -m py_compile job_radar/gui/worker_thread.py && echo 'Syntax OK'`
Run: `python -m py_compile job_radar/sources.py && echo 'Syntax OK'`
Grep to confirm real search pipeline:
- `grep -c "fetch_all\|score_job\|generate_report\|mark_seen" job_radar/gui/worker_thread.py` should be >= 4
- `grep -c "search_complete" job_radar/gui/worker_thread.py` should be >= 1
- `grep -c "source_job_counts" job_radar/sources.py` should be >= 2
  </verify>
  <done>
SearchWorker class executes the full search pipeline (fetch -> filter -> score -> track -> report) in a worker thread. sources.py on_source_progress callback now includes per-source job count as 5th argument. SearchWorker sends source_complete queue messages with job_count (e.g., enabling "Dice: 12 jobs found" display). MockSearchWorker and all existing test infrastructure remain unchanged.
  </done>
</task>

</tasks>

<verification>
1. All three files compile: `python -m py_compile job_radar/gui/search_controls.py && python -m py_compile job_radar/gui/worker_thread.py && python -m py_compile job_radar/sources.py`
2. New classes import alongside existing: `python -c "from job_radar.gui.search_controls import SearchControls; from job_radar.gui.worker_thread import SearchWorker, MockSearchWorker; print('All OK')"`
3. Mock workers not broken: `python -c "from job_radar.gui.worker_thread import create_mock_worker; import queue; q = queue.Queue(); w, t = create_mock_worker(q); print('Mock factory OK')"`
4. SearchWorker has correct message types: grep for source_started, source_complete, search_complete, cancelled, error
5. sources.py passes per-source job count: `grep "source_job_counts" job_radar/sources.py` confirms tracking dict exists
</verification>

<success_criteria>
- SearchControls provides date range, min score, and new-only toggle with get_config() API
- SearchWorker executes the full real search pipeline (fetch_all -> score_job -> filter -> mark_seen -> generate_report)
- sources.py on_source_progress callback includes per-source job count as 5th parameter
- Queue messages include source-level progress with job count (source_complete includes job_count) and search completion with total job count + report path
- Mock workers remain intact for testing
- No modifications to main_window.py (integration happens in Plan 03)
</success_criteria>

<output>
After completion, create `.planning/phases/29-profile-setup-search-controls/29-02-SUMMARY.md`
</output>

---
phase: 10-ux-polish
plan: 02
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - job_radar/search.py
  - job_radar/sources.py
autonomous: true

must_haves:
  truths:
    - "User sees 'Fetching Dice... (1/4)' WHEN fetch starts for that source (real-time, not after-the-fact)"
    - "User sees 'Dice complete' WHEN all queries for that source finish (real-time confirmation)"
    - "User sees friendly error message for network failures (no Python tracebacks, no HTTP codes)"
    - "User sees encouraging message with suggestions when zero results are found"
    - "All errors logged to error file with full technical details for debugging"
  artifacts:
    - path: "job_radar/sources.py"
      provides: "Source-level progress tracking in fetch_all with START/COMPLETE callbacks, per-source error handling"
      contains: "on_source_progress"
    - path: "job_radar/search.py"
      provides: "Progress display callback, friendly error messages for all failure modes"
      contains: "on_source_progress"
  key_links:
    - from: "job_radar/search.py"
      to: "job_radar/sources.py"
      via: "on_source_progress callback passed to fetch_all"
      pattern: "on_source_progress"
    - from: "job_radar/search.py"
      to: "job_radar/banner.py"
      via: "log_error_to_file for non-fatal error logging"
      pattern: "log_error_to_file"
---

<objective>
Add source-level progress indicators during job fetching and wrap all error paths with friendly user-facing messages that log technical details to file.

Purpose: Users see reassuring progress during the 10-30 second fetch (UX-01) and never see Python tracebacks on errors (UX-02).
Output: Updated sources.py with source-level progress and search.py with progress display and friendly error handling.
</objective>

<execution_context>
@/Users/coryebert/.claude/get-shit-done/workflows/execute-plan.md
@/Users/coryebert/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-ux-polish/10-CONTEXT.md
@.planning/phases/10-ux-polish/10-RESEARCH.md
@.planning/phases/10-ux-polish/10-01-SUMMARY.md
@job_radar/sources.py
@job_radar/search.py
@job_radar/banner.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add source-level progress tracking to sources.py fetch_all</name>
  <files>job_radar/sources.py</files>
  <action>
  Modify `fetch_all()` in sources.py to track and report progress at the SOURCE level (not query level) with REAL-TIME feedback. Per CONTEXT.md: "Fetching Indeed... (1/4)" format, one line per source, no job counts during fetch. Per user decision: "Progress messages should feel like they're making progress — users need reassurance during the 10-30 second fetch."

  **Critical timing requirement:** The callback must fire TWICE per source:
  - STARTED: When the FIRST query for that source is SUBMITTED (before any fetching happens for that source)
  - COMPLETE: When the LAST query for that source FINISHES (after all fetching is done for that source)

  This means "Fetching Dice... (1/4)" appears the moment Dice starts, NOT after Dice finishes.

  **Changes to fetch_all():**

  1. **Add a new callback parameter** `on_source_progress` alongside the existing `on_progress`:
     - Signature: `on_source_progress(source_name: str, count: int, total: int, status: str)` where status is `'started'` or `'complete'`, and count/total are source counts (not query counts)
     - Keep the existing `on_progress` callback for backward compatibility (still fires per query)

  2. **Fire START callback before submitting queries** — Group queries by source. Before submitting each source's queries to the thread pool, fire `on_source_progress(display_name, sources_started, total_sources, 'started')`. This ensures "Fetching Dice..." prints WHEN fetching begins, not after.

  3. **Fire COMPLETE callback when all queries for a source finish** — Track `source_name -> completed_queries` and `source_name -> total_queries`. In the as_completed loop, when a source's completed count reaches its total, fire `on_source_progress(display_name, sources_completed, total_sources, 'complete')`.

  4. **Determine source count** — Count unique sources from the queries list. The total is the number of unique sources (typically 4).

  5. **Error handling per source** — When a query fails (exception in future.result()), log the error using the existing `log.error()` but also catch the exception so it doesn't propagate. Still count the failed query toward source completion (so the "complete" callback fires even if some queries failed).

  **Implementation approach:**

  ```python
  def fetch_all(profile: dict, on_progress=None, on_source_progress=None) -> list[JobResult]:
      queries = build_search_queries(profile)
      all_results = []
      seen = set()
      total = len(queries)
      completed = 0

      # Source-level tracking
      source_names = list(dict.fromkeys(q["source"] for q in queries))  # unique, ordered
      source_query_counts = {}
      source_completed = {}
      for q in queries:
          source_query_counts[q["source"]] = source_query_counts.get(q["source"], 0) + 1
          source_completed[q["source"]] = 0
      sources_started = 0
      sources_done = 0
      total_sources = len(source_names)

      # ... existing run_query logic (unchanged) ...

      log.info("Running %d search queries in parallel...", len(queries))
      with ThreadPoolExecutor(max_workers=6) as executor:
          # Submit queries grouped by source — fire START callback before each source's queries
          futures = {}
          started_sources = set()
          for q in queries:
              source = q["source"]
              if source not in started_sources:
                  started_sources.add(source)
                  sources_started += 1
                  if on_source_progress:
                      display_name = _SOURCE_DISPLAY_NAMES.get(source, source)
                      on_source_progress(display_name, sources_started, total_sources, "started")
              futures[executor.submit(run_query, q)] = q

          # Process results as they complete — fire COMPLETE callback when source finishes
          for future in as_completed(futures):
              q = futures[future]
              completed += 1
              try:
                  results = future.result()
                  for r in results:
                      key = (r.title.lower().strip(), r.company.lower().strip())
                      if key not in seen:
                          seen.add(key)
                          all_results.append(r)
              except Exception as e:
                  log.error("Query failed (%s): %s", q, e)
              if on_progress:
                  on_progress(completed, total, q["source"])

              # Source-level completion tracking
              source = q["source"]
              source_completed[source] += 1
              if source_completed[source] == source_query_counts[source]:
                  sources_done += 1
                  if on_source_progress:
                      display_name = _SOURCE_DISPLAY_NAMES.get(source, source)
                      on_source_progress(display_name, sources_done, total_sources, "complete")
  ```

  **Note on submission order:** Since queries are built in source order (all Dice queries, then all HN queries, etc.) in build_search_queries, the submission loop naturally processes sources in order. The START callbacks fire in sequence BEFORE queries begin executing. With ThreadPoolExecutor(max_workers=6), all queries submit fast (non-blocking), so all START messages print almost immediately, then COMPLETE messages trickle in as fetches finish. This creates the desired timeline:

  ```
  Fetching Dice... (1/4)           <-- immediate (submission)
  Fetching HN Hiring... (2/4)     <-- immediate (submission)
  Fetching RemoteOK... (3/4)      <-- immediate (submission)
  Fetching We Work Remotely... (4/4) <-- immediate (submission)
  [seconds pass while fetches happen]
  RemoteOK complete               <-- when RemoteOK queries all finish
  We Work Remotely complete       <-- when WWR queries all finish
  HN Hiring complete              <-- when HN queries all finish
  Dice complete                   <-- when Dice queries all finish
  ```

  6. **Add source display name mapping** at module level:
  ```python
  _SOURCE_DISPLAY_NAMES = {
      "dice": "Dice",
      "hn_hiring": "HN Hiring",
      "remoteok": "RemoteOK",
      "weworkremotely": "We Work Remotely",
  }
  ```

  Do NOT change any existing fetcher functions (fetch_dice, fetch_hn_hiring, etc.).
  Do NOT change the return type or existing behavior of fetch_all.
  Keep the existing `on_progress` callback firing per-query for backward compatibility.
  </action>
  <verify>
  Run: `python -c "
from job_radar.sources import build_search_queries, fetch_all
profile = {'name': 'Test', 'target_titles': ['Python Developer'], 'core_skills': ['python']}
queries = build_search_queries(profile)
sources = list(set(q['source'] for q in queries))
print(f'Sources: {sources}')
print(f'Queries: {len(queries)}')
print('Source tracking logic imports OK')
"` to verify the module loads without errors.
  </verify>
  <done>
  - fetch_all() accepts on_source_progress callback with signature (source_name, count, total, status)
  - Callback fires with status='started' BEFORE queries for each source begin executing (real-time "Fetching..." messages)
  - Callback fires with status='complete' AFTER all queries for each source finish (real-time "complete" messages)
  - Progress reports use display names (Dice, HN Hiring, RemoteOK, We Work Remotely)
  - Source-level tracking counts sources started and sources completed independently
  - Existing on_progress callback still works for backward compatibility
  - No changes to individual fetcher functions
  </done>
</task>

<task type="auto">
  <name>Task 2: Add progress display and friendly error handling to search.py main()</name>
  <files>job_radar/search.py</files>
  <action>
  Update `main()` in search.py to display source-level progress and handle all errors with friendly messages. Per CONTEXT.md: plain text only, no colors in progress, stack vertically, friendly+actionable errors, log technical details.

  **1. Progress display — replace current _on_fetch_progress:**

  Replace the existing `_on_fetch_progress` callback (which uses carriage return `\r` for in-place updates) with a new source-level progress callback that handles both START and COMPLETE events:

  ```python
  def _on_source_progress(source_name, count, total, status):
      """Display source-level progress — plain text, one line per event.

      Called TWICE per source:
      - status='started': prints "Fetching {source}... (N/M)" when source begins
      - status='complete': prints "{source} complete" when source finishes

      This provides real-time feedback: users see "Fetching..." the moment
      a source starts, not after it's already done.
      """
      if status == "started":
          print(f"  Fetching {source_name}... ({count}/{total})", flush=True)
      elif status == "complete":
          print(f"  {source_name} complete", flush=True)
  ```

  Update the fetch_all call to pass this as `on_source_progress`:
  ```python
  all_results = fetch_all(profile, on_source_progress=_on_source_progress)
  ```

  Remove the old `_on_fetch_progress` function and remove the old `on_progress=_on_fetch_progress` argument.

  **2. Friendly error handling in main() — wrap key steps:**

  Import `log_error_to_file` from `job_radar.banner` at the top of the function (or at module level with a try/except for safety).

  **Profile loading errors** — The existing load_profile and load_profile_with_recovery already handle their own errors. No changes needed there.

  **Fetch errors** — Wrap the fetch_all call:
  ```python
  try:
      all_results = fetch_all(profile, on_source_progress=_on_source_progress)
  except Exception as e:
      print("\nCouldn't fetch job listings — check your internet connection")
      log_error_to_file(f"Fetch failed: {e}", exception=e)
      sys.exit(1)
  ```

  **Zero results after scoring** — After the scoring step, if `scored` is empty (no jobs passed scoring), show an encouraging message:
  ```python
  if not scored:
      print(f"\n  No matches found — try broadening your skills or lowering min_score")
      print(f"  Current min_score: {min_score}")
      # Still continue to generate report (it will show manual URLs)
  ```
  This replaces any existing zero-results handling. Do NOT exit — continue to generate the report (it includes manual check URLs which are still useful).

  **Report generation errors** — The existing try/except around generate_report already handles this. Update the error message to be friendlier:
  ```python
  except Exception as e:
      print(f"\nReport generation failed — your results were found but couldn't be saved")
      print(f"Try running again or check available disk space")
      from .banner import log_error_to_file
      log_error_to_file(f"Report generation failed: {e}", exception=e)
      sys.exit(1)
  ```

  **3. Use flush=True** on all progress-related print() calls to ensure output appears immediately.

  **4. Remove the logger suppression hack** — The current code temporarily changes log levels for fetch_loggers to suppress output during fetch. With source-level progress (not query-level), this is less necessary. However, keep it for non-verbose mode to avoid interleaving log output with progress messages. This is a judgment call — if the output looks clean without the hack, remove it; if logs interleave with progress, keep it.

  Do NOT change the scoring, date filtering, tracking, or report generation logic.
  Do NOT change the argument parsing (that was done in Plan 01).
  Do NOT add colors to progress messages (CONTEXT.md: plain text only for progress).
  </action>
  <verify>
  Run: `cd "/Users/coryebert/Documents/Job Hunt Python/Project Folder/Job-Radar" && python -m job_radar --no-wizard --dry-run --profile profiles/_template.json 2>&1 | head -30` to verify the app still works end-to-end with updated search.py.
  Run: `cd "/Users/coryebert/Documents/Job Hunt Python/Project Folder/Job-Radar" && python -m pytest tests/ -x -q` to verify all existing tests pass.
  </verify>
  <done>
  - _on_source_progress accepts status parameter ('started'|'complete') and routes to different messages
  - When status='started': prints "Fetching Dice... (1/4)" — appears when fetch BEGINS (real-time)
  - When status='complete': prints "Dice complete" — appears when fetch ENDS (real-time)
  - Each event gets its own line (vertical stacking, no carriage return)
  - Network errors show friendly message ("Couldn't fetch job listings — check your internet connection")
  - Zero results show encouraging message with suggestion to broaden skills or lower min_score
  - Report errors show friendly message with suggestion
  - All technical details logged to error file (never shown to user)
  - All existing tests pass
  </done>
</task>

</tasks>

<verification>
1. Run `python -m job_radar --no-wizard --dry-run --profile profiles/_template.json` to verify updated progress and error flow
2. Run `python -m pytest tests/ -x -q` to confirm no regressions
3. Verify search.py no longer uses `\r` carriage return for progress
4. Verify error messages in search.py are friendly and actionable (no tracebacks, no HTTP codes)
</verification>

<success_criteria>
- "Fetching {source}..." messages appear WHEN each source STARTS fetching (real-time, not after-the-fact)
- "{source} complete" messages appear WHEN each source FINISHES fetching (real-time confirmation)
- Progress callback fires twice per source: once at start (status='started'), once at end (status='complete')
- All error paths show friendly messages to user and log technical details to file
- Zero results show encouraging suggestion message
- No Python tracebacks shown to users under any error condition
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/10-ux-polish/10-02-SUMMARY.md`
</output>

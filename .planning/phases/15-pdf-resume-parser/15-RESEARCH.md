# Phase 15: PDF Resume Parser - Research

**Researched:** 2026-02-10
**Domain:** Resume PDF text extraction and field parsing for CLI wizard
**Confidence:** HIGH

## Summary

Phase 15 implements PDF resume import as an optional first step in the wizard setup flow. Users can upload a PDF resume to pre-fill profile fields (name, years of experience, job titles, skills), with full editing capability before saving. The implementation uses pdfplumber for text extraction, regex patterns for field parsing, and integrates seamlessly with the existing questionary-based wizard.

The technical approach follows established patterns: pdfplumber extracts raw text, regex patterns identify structured fields, validation ensures data quality, and the wizard consumes extracted data as default values. Error handling is defensive‚Äîall PDF failures degrade gracefully to manual entry without blocking wizard completion.

**Primary recommendation:** Use pdfplumber 0.11.9+ for text extraction, implement separate pdf_parser.py module for isolation, validate PDFs before parsing (text-extractable, size limits, encryption detection), and pre-fill wizard prompts with extracted data as editable defaults.

## Standard Stack

The established libraries for PDF resume parsing in Python:

### Core

| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| pdfplumber | 0.11.9+ | Extract text from PDF resumes | Industry standard for structured PDF text extraction. Built on pdfminer.six with superior table/layout handling. Actively developed (latest release Jan 5, 2026). Python 3.8-3.14 support matches project requirement (3.10+). Already researched in STACK.md. |
| python-dateutil | 2.9.0+ | Parse work history dates | De facto standard for flexible date parsing. Handles fuzzy parsing ("Jan 2020 - Present", "2020-2023", etc.) without format specifications. Required for calculating years of experience from resume dates. |

### Supporting

| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| questionary | 2.0.1+ | File path prompts and validation | Already in project. Use questionary.path() for file picker with autocomplete, questionary.select() for upload vs manual choice. Integrates with existing wizard validators. |
| Pillow | 11.0.0+ | Image processing for pdfplumber | Already in project as build dependency. Optional for pdfplumber's .to_image() debugging. Not required for text extraction. |

### Alternatives Considered

| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| pdfplumber | pypdf | pypdf (successor to PyPDF2) focuses on PDF manipulation (merge/split). pdfplumber excels at structured text extraction‚Äîbetter fit for resume parsing. |
| pdfplumber | PyMuPDF (fitz) | Faster but requires non-Python MuPDF installation. Adds complexity to PyInstaller builds. pdfplumber is pure Python (via pdfminer.six). |
| python-dateutil | Manual regex | dateutil handles edge cases (abbreviated months, varied formats, fuzzy text). Manual regex requires maintaining dozens of patterns. |
| questionary.path | questionary.text | .path() provides autocomplete and path normalization. .text() requires manual path validation. Use .path() for better UX. |

**Installation:**

Add to `pyproject.toml` dependencies:
```toml
dependencies = [
    # ... existing dependencies ...
    "pdfplumber>=0.11.9",      # NEW: PDF parsing (Phase 15)
    "python-dateutil>=2.9.0",  # NEW: Date parsing (Phase 15)
]
```

Install:
```bash
pip install pdfplumber>=0.11.9 python-dateutil>=2.9.0
# Or update from pyproject.toml
pip install -e .
```

## Architecture Patterns

### Recommended Project Structure

```
job_radar/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ wizard.py           # ENHANCED: Add PDF import step
‚îú‚îÄ‚îÄ pdf_parser.py       # NEW: Resume parsing module
‚îú‚îÄ‚îÄ sources.py          # (no changes)
‚îú‚îÄ‚îÄ scoring.py          # (no changes)
‚îî‚îÄ‚îÄ ...
```

### Pattern 1: PDF Parser Module (Separation of Concerns)

**What:** Standalone module for resume text extraction and field parsing, separate from wizard UI logic.

**When to use:** When adding PDF parsing to interactive CLI wizard.

**Example:**

```python
# New file: job_radar/pdf_parser.py

"""Resume PDF parsing and data extraction.

Validates PDFs, extracts text via pdfplumber, parses structured fields
using regex patterns, and returns dict for wizard pre-population.
"""

import re
from pathlib import Path
from datetime import datetime
from dateutil import parser as dateutil_parser

try:
    import pdfplumber
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False


class PDFValidationError(Exception):
    """Raised when PDF validation fails (encrypted, image-only, corrupted)."""
    pass


def validate_pdf_file(pdf_path: Path) -> None:
    """Validate PDF file before parsing.

    Checks:
    - File exists and has .pdf extension
    - File size <= 5 MB
    - PDF is text-extractable (not image-only)
    - PDF is not encrypted/password-protected

    Parameters
    ----------
    pdf_path : Path
        Path to PDF file

    Raises
    ------
    PDFValidationError
        If validation fails with actionable error message
    """
    if not PDF_SUPPORT:
        raise PDFValidationError(
            "pdfplumber not installed. Install with: pip install pdfplumber"
        )

    # Check file exists
    if not pdf_path.exists():
        raise PDFValidationError(
            f"File not found: {pdf_path}"
        )

    # Check extension
    if pdf_path.suffix.lower() != '.pdf':
        raise PDFValidationError(
            "File must be a PDF (.pdf extension required)"
        )

    # Check file size (5 MB limit per CONTEXT.md decision)
    file_size_bytes = pdf_path.stat().st_size
    max_size_bytes = 5 * 1024 * 1024  # 5 MB
    if file_size_bytes > max_size_bytes:
        raise PDFValidationError(
            f"File size exceeds 5 MB limit. Please use a smaller PDF or fill manually."
        )

    # Check if PDF is text-extractable (not image-only)
    # Open PDF with pdfplumber to check for encryption and text content
    try:
        with pdfplumber.open(pdf_path, strict_metadata=False) as pdf:
            if len(pdf.pages) == 0:
                raise PDFValidationError(
                    "PDF has no pages. The file may be corrupted."
                )

            # Try to extract text from first page
            first_page_text = pdf.pages[0].extract_text()

            # If extract_text() returns None or empty string, PDF is image-only
            if not first_page_text or not first_page_text.strip():
                raise PDFValidationError(
                    "This PDF appears to be image-based. Please use a text-based resume or fill manually."
                )

    except pdfplumber.pdfminer.pdfdocument.PDFPasswordIncorrect:
        # Encrypted PDF detected
        raise PDFValidationError(
            "This PDF is password-protected. Please use an unencrypted resume or fill manually."
        )

    except pdfplumber.pdfminer.pdfparser.PDFSyntaxError as e:
        # Corrupted or malformed PDF
        raise PDFValidationError(
            f"Unable to read PDF file. The file may be corrupted. Try a different file or fill manually."
        )

    except Exception as e:
        # Catch-all for unexpected pdfplumber errors
        raise PDFValidationError(
            f"Unable to read PDF file: {str(e)}. Try a different file or fill manually."
        )


def extract_resume_data(pdf_path: str | Path) -> dict:
    """Extract structured data from a resume PDF.

    Validates PDF, extracts text via pdfplumber, and parses fields using
    regex patterns. Returns dict with extracted data for wizard pre-fill.

    Parameters
    ----------
    pdf_path : str | Path
        Path to resume PDF file

    Returns
    -------
    dict
        Extracted data with keys: name, years_experience, titles, skills
        Only includes keys where extraction succeeded. Empty dict if all fail.

    Raises
    ------
    PDFValidationError
        If PDF validation fails (encryption, image-only, corrupted, size limit)
    """
    pdf_path = Path(pdf_path)

    # Validate PDF before parsing
    validate_pdf_file(pdf_path)

    # Extract text from all pages
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        raise PDFValidationError(f"Failed to extract text from PDF: {e}")

    if not text.strip():
        raise PDFValidationError("PDF contains no extractable text")

    # Parse extracted text
    extracted = {}

    # Extract name (heuristic: first non-contact line at top of document)
    name = _extract_name(text)
    if name:
        extracted['name'] = name

    # Extract years of experience
    years = _extract_years_experience(text)
    if years is not None:
        extracted['years_experience'] = years

    # Extract job titles
    titles = _extract_job_titles(text)
    if titles:
        extracted['titles'] = titles

    # Extract skills
    skills = _extract_skills(text)
    if skills:
        extracted['skills'] = skills

    return extracted


def _extract_name(text: str) -> str | None:
    """Extract name from top of resume.

    Heuristic: First non-empty line that doesn't contain contact info
    (email, phone, URL) and is properly capitalized.

    Parameters
    ----------
    text : str
        Full resume text

    Returns
    -------
    str | None
        Extracted name or None if not found
    """
    lines = [line.strip() for line in text.split('\n') if line.strip()]

    # Regex pattern for contact info (email, phone, URL)
    contact_pattern = re.compile(
        r'@|\.com|\.edu|\.org|http|www\.|'
        r'\d{3}[-.\s]?\d{3}[-.\s]?\d{4}|'  # Phone: 123-456-7890, 123.456.7890, etc.
        r'phone|tel|email|linkedin',
        re.IGNORECASE
    )

    # Check first 5 lines for name
    for line in lines[:5]:
        # Skip lines with contact info
        if contact_pattern.search(line):
            continue

        # Skip lines that are all caps (likely section headers)
        if line.isupper() and len(line) > 20:
            continue

        # Check if line looks like a name (2-5 words, proper capitalization)
        words = line.split()
        if 2 <= len(words) <= 5:
            # Check if words are capitalized (allow for middle initials)
            if all(w[0].isupper() or w in ['von', 'van', 'de', 'la'] for w in words if w):
                return line

    return None


def _extract_years_experience(text: str) -> int | None:
    """Extract years of professional experience from resume.

    Strategies:
    1. Look for explicit mention: "X years of experience"
    2. Calculate from work history dates (sum of all employment periods)

    Parameters
    ----------
    text : str
        Full resume text

    Returns
    -------
    int | None
        Years of experience or None if not found
    """
    # Strategy 1: Explicit mention
    # Patterns: "5 years of experience", "5+ years experience", "5 yrs exp"
    exp_pattern = re.compile(
        r'(\d+)\+?\s*(?:years?|yrs?)\s+(?:of\s+)?(?:professional\s+)?(?:work\s+)?experience',
        re.IGNORECASE
    )
    match = exp_pattern.search(text)
    if match:
        return int(match.group(1))

    # Strategy 2: Calculate from work history dates
    # Look for date ranges in work experience section
    # Common formats: "Jan 2020 - Present", "2020-2023", "03/2020 - 06/2023"

    # Find work experience section
    exp_section_start = None
    for pattern in [
        r'\b(?:work\s+)?experience\b',
        r'\b(?:employment\s+)?history\b',
        r'\bprofessional\s+experience\b'
    ]:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            exp_section_start = match.start()
            break

    if exp_section_start is None:
        return None

    # Extract text from experience section (next ~2000 chars)
    exp_text = text[exp_section_start:exp_section_start + 2000]

    # Find all date ranges
    # Pattern: Month YYYY - Month YYYY, YYYY-YYYY, MM/YYYY - MM/YYYY
    date_range_pattern = re.compile(
        r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\.?\s+\d{4}\s*[-‚Äì‚Äî]\s*(?:(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\.?\s+\d{4}|Present|Current)',
        re.IGNORECASE
    )

    date_ranges = date_range_pattern.findall(exp_text)

    if not date_ranges:
        # Try numeric format: 2020-2023, 03/2020 - 06/2023
        date_range_pattern = re.compile(r'\d{4}\s*[-‚Äì‚Äî]\s*(?:\d{4}|Present|Current)', re.IGNORECASE)
        date_ranges = date_range_pattern.findall(exp_text)

    if not date_ranges:
        return None

    # Calculate total years from date ranges
    total_months = 0
    for date_range in date_ranges[:10]:  # Limit to first 10 jobs
        # Parse start and end dates
        parts = re.split(r'\s*[-‚Äì‚Äî]\s*', date_range)
        if len(parts) != 2:
            continue

        start_str, end_str = parts

        try:
            # Parse start date
            start_date = dateutil_parser.parse(start_str, fuzzy=True)

            # Parse end date (handle "Present" / "Current")
            if re.search(r'present|current', end_str, re.IGNORECASE):
                end_date = datetime.now()
            else:
                end_date = dateutil_parser.parse(end_str, fuzzy=True)

            # Calculate months difference
            months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)
            total_months += months

        except Exception:
            # Skip ranges that can't be parsed
            continue

    if total_months > 0:
        return round(total_months / 12)

    return None


def _extract_job_titles(text: str) -> list[str] | None:
    """Extract job titles from work experience section.

    Heuristic: Lines immediately before date ranges in experience section,
    filtering out company names and common section headers.

    Parameters
    ----------
    text : str
        Full resume text

    Returns
    -------
    list[str] | None
        Extracted job titles or None if not found
    """
    # Find work experience section
    exp_section_start = None
    for pattern in [
        r'\b(?:work\s+)?experience\b',
        r'\b(?:employment\s+)?history\b',
        r'\bprofessional\s+experience\b'
    ]:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            exp_section_start = match.start()
            break

    if exp_section_start is None:
        return None

    # Extract text from experience section
    exp_text = text[exp_section_start:exp_section_start + 2000]

    # Common job title patterns (based on Job Radar domain)
    title_keywords = [
        r'engineer', r'developer', r'architect', r'manager', r'analyst',
        r'designer', r'consultant', r'specialist', r'lead', r'senior',
        r'junior', r'principal', r'staff', r'director', r'coordinator'
    ]

    title_pattern = re.compile(
        r'\b(?:' + '|'.join(title_keywords) + r')\b',
        re.IGNORECASE
    )

    titles = []
    lines = exp_text.split('\n')

    for line in lines[:20]:  # First 20 lines of experience section
        line = line.strip()
        if not line:
            continue

        # Check if line contains job title keywords
        if title_pattern.search(line):
            # Filter out lines that look like company names or locations
            if not re.search(r'\b(?:inc|llc|corp|ltd|company)\b', line, re.IGNORECASE):
                # Clean up title (remove date ranges, locations)
                clean_title = re.sub(r'\d{4}\s*[-‚Äì‚Äî]\s*(?:\d{4}|Present)', '', line)
                clean_title = re.sub(r'\|.*$', '', clean_title)  # Remove "| Company Name"
                clean_title = clean_title.strip()

                if clean_title and len(clean_title) < 80:  # Reasonable title length
                    titles.append(clean_title)

        if len(titles) >= 3:
            break

    return titles[:3] if titles else None


def _extract_skills(text: str) -> list[str] | None:
    """Extract skills from resume (technical skills, tools, languages).

    Strategies:
    1. Look for "Skills" section and parse as comma/bullet-separated list
    2. Match against common technical skill keywords

    Parameters
    ----------
    text : str
        Full resume text

    Returns
    -------
    list[str] | None
        Extracted skills or None if not found
    """
    # Find skills section
    skills_section_start = None
    for pattern in [
        r'\b(?:technical\s+)?skills?\b',
        r'\bcore\s+competencies\b',
        r'\btechnologies\b',
        r'\btools?\s+and\s+technologies\b'
    ]:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            skills_section_start = match.start()
            break

    if skills_section_start is None:
        return None

    # Extract text from skills section (next ~500 chars)
    skills_text = text[skills_section_start:skills_section_start + 500]

    # Stop at next major section header
    next_section = re.search(
        r'\n\s*\b(?:experience|education|projects|certifications)\b',
        skills_text,
        re.IGNORECASE
    )
    if next_section:
        skills_text = skills_text[:next_section.start()]

    # Parse skills as comma/bullet/pipe-separated list
    # Remove section header line
    skills_lines = skills_text.split('\n')[1:]
    skills_text = ' '.join(skills_lines)

    # Split by common separators
    skills = re.split(r'[,;‚Ä¢\|\n]+', skills_text)
    skills = [s.strip() for s in skills if s.strip()]

    # Filter out non-skill text (section headers, full sentences)
    filtered_skills = []
    for skill in skills:
        # Skip if too long (likely a sentence, not a skill)
        if len(skill) > 50:
            continue

        # Skip if contains common section header words
        if re.search(r'\b(?:include|such as|proficient in|experience with)\b', skill, re.IGNORECASE):
            continue

        # Keep if looks like a skill (1-5 words, possibly with symbols)
        words = skill.split()
        if 1 <= len(words) <= 5:
            filtered_skills.append(skill)

    return filtered_skills[:20] if filtered_skills else None
```

**Source:** [pdfplumber PyPI](https://pypi.org/project/pdfplumber/), [pdfplumber GitHub](https://github.com/jsvine/pdfplumber), [ARCHITECTURE.md (v1.2.0)](/.planning/research/ARCHITECTURE.md)

### Pattern 2: Wizard Integration (Pre-Fill with Defaults)

**What:** PDF parsing as optional first step in wizard, pre-filling subsequent prompts with extracted data.

**When to use:** When extending existing wizard with resume import feature.

**Example:**

```python
# In wizard.py (ENHANCED)

def run_setup_wizard() -> bool:
    """Run interactive setup wizard with optional PDF import.

    Per CONTEXT.md decisions:
    - PDF upload offered FIRST THING (opening choice)
    - User sees "Upload resume or fill manually?" before any manual prompts
    - Pre-fill wizard prompts with extracted data as default values
    - User can edit any pre-filled field inline
    - Disclaimer shown once after parsing
    - Skip mechanism: questionary.select with equal choices
    """
    from .paths import get_data_dir

    # Wizard header
    print("\n" + "=" * 60)
    print("üéØ Job Radar - First Time Setup")
    print("=" * 60)

    # NEW: PDF import prompt (per CONTEXT.md: upload timing decision)
    print("\nüí° Speed up setup: Upload your resume PDF to auto-fill fields.\n")

    upload_choice = questionary.select(
        "How would you like to create your profile?",
        choices=[
            "Upload resume PDF",
            "Fill manually",
        ],
        style=custom_style
    ).ask()

    # Extract data from PDF if user chooses upload
    extracted_data = {}
    if upload_choice and "PDF" in upload_choice:
        pdf_path_str = questionary.path(
            "Path to your resume PDF:",
            only_directories=False,
            validate=lambda p: (
                Path(p).suffix.lower() == '.pdf' and Path(p).exists()
            ) or "Please enter a valid path to a PDF file",
            style=custom_style
        ).ask()

        if pdf_path_str:
            print(f"\nüìÑ Parsing resume PDF...\n")
            try:
                from .pdf_parser import extract_resume_data, PDFValidationError
                extracted_data = extract_resume_data(pdf_path_str)

                # Show disclaimer (per CONTEXT.md: once after parsing)
                print("‚úÖ Resume parsed successfully!")
                print("\n‚ö†Ô∏è  Please review - extraction may contain errors\n")

                # Show what was extracted
                if extracted_data:
                    print("üìã Extracted fields:")
                    for key in extracted_data:
                        print(f"   ‚Ä¢ {key}")
                    print()

            except PDFValidationError as e:
                # Per CONTEXT.md: show specific actionable error message
                print(f"\n‚ùå {str(e)}\n")

                fallback = questionary.confirm(
                    "Would you like to fill your profile manually?",
                    default=True,
                    style=custom_style
                ).ask()

                if not fallback:
                    return False

                extracted_data = {}

            except Exception as e:
                # Catch-all for unexpected errors
                print(f"\n‚ö†Ô∏è  PDF parsing failed: {e}")
                print("Continuing with manual entry...\n")
                extracted_data = {}

    print("Tip: Type /back at any prompt to return to the previous question.\n")

    # Sequential prompts with extracted data as defaults
    # Per CONTEXT.md: pre-fill wizard prompts with extracted data
    questions = [
        {
            'key': 'name',
            'type': 'text',
            'message': "What's your name?",
            'instruction': "e.g., John Doe",
            'validator': NonEmptyValidator(),
            'required': True,
        },
        {
            'key': 'years_experience',
            'type': 'text',
            'message': "Years of professional experience:",
            'instruction': "Enter a number (e.g., 3, 5, 10)",
            'validator': YearsExperienceValidator(),
            'required': True,
        },
        # ... rest of questions ...
    ]

    answers = {}
    idx = 0

    while idx < len(questions):
        q = questions[idx]
        key = q['key']

        # Build prompt kwargs
        prompt_kwargs = {
            'message': q['message'],
            'style': custom_style,
        }

        if q['instruction']:
            prompt_kwargs['instruction'] = q['instruction']

        if q.get('validator'):
            prompt_kwargs['validate'] = q['validator']

        # Pre-fill with extracted data if available (per CONTEXT.md: pre-display validation)
        if key in extracted_data:
            value = extracted_data[key]

            # Sanity check extracted value before using as default
            if key == 'years_experience' and isinstance(value, int) and value >= 0:
                prompt_kwargs['default'] = str(value)
            elif key == 'name' and isinstance(value, str) and value.strip():
                prompt_kwargs['default'] = value
            elif key == 'titles' and isinstance(value, list) and value:
                prompt_kwargs['default'] = ', '.join(value)
            elif key == 'skills' and isinstance(value, list) and value:
                prompt_kwargs['default'] = ', '.join(value)

        # Pre-fill with previous answer if going back
        elif key in answers:
            if q['type'] == 'text':
                prompt_kwargs['default'] = str(answers[key])

        # Use question default if set
        elif q.get('default') is not None and q['type'] == 'text':
            prompt_kwargs['default'] = q['default']

        # Ask question
        if q['type'] == 'text':
            result = questionary.text(**prompt_kwargs).ask()
        elif q['type'] == 'confirm':
            if key in answers:
                prompt_kwargs['default'] = answers[key]
            elif q.get('default') is not None:
                prompt_kwargs['default'] = q['default']
            result = questionary.confirm(**prompt_kwargs).ask()

        # Handle Ctrl+C, /back, store answer, advance
        # ... existing wizard logic continues unchanged ...
```

**Source:** [Questionary Documentation](https://questionary.readthedocs.io/en/stable/pages/types.html), [CONTEXT.md (Phase 15 decisions)](/.planning/phases/15-pdf-resume-parser/15-CONTEXT.md)

### Pattern 3: File Validation Before Processing

**What:** Validate file size, extension, and PDF properties before expensive text extraction.

**When to use:** When accepting user-uploaded files to prevent resource exhaustion and provide early feedback.

**Example:**

```python
def validate_pdf_file(pdf_path: Path) -> None:
    """Validate PDF file before parsing.

    Per CONTEXT.md decisions:
    - 5 MB maximum file size enforced
    - PDF only (.pdf extension required)
    - Text-extractable check: pdfplumber.extract_text() returns non-empty string
    - Specific error messages for common failures
    """
    # Check file size FIRST (before opening PDF)
    # Per research: os.path.getsize() or Path.stat().st_size
    file_size_bytes = pdf_path.stat().st_size
    max_size_bytes = 5 * 1024 * 1024  # 5 MB limit

    if file_size_bytes > max_size_bytes:
        raise PDFValidationError(
            "File size exceeds 5 MB limit. Please use a smaller PDF or fill manually."
        )

    # Check extension
    if pdf_path.suffix.lower() != '.pdf':
        raise PDFValidationError(
            "File must be a PDF (.pdf extension required)"
        )

    # Check text-extractable (per CONTEXT.md: technical check)
    try:
        with pdfplumber.open(pdf_path, strict_metadata=False) as pdf:
            if len(pdf.pages) == 0:
                raise PDFValidationError(
                    "PDF has no pages. The file may be corrupted."
                )

            # Per CONTEXT.md: "text-extractable" = extract_text() returns non-empty
            first_page_text = pdf.pages[0].extract_text()

            if not first_page_text or not first_page_text.strip():
                raise PDFValidationError(
                    "This PDF appears to be image-based. Please use a text-based resume or fill manually."
                )

    except pdfplumber.pdfminer.pdfdocument.PDFPasswordIncorrect:
        raise PDFValidationError(
            "This PDF is password-protected. Please use an unencrypted resume or fill manually."
        )

    except pdfplumber.pdfminer.pdfparser.PDFSyntaxError:
        raise PDFValidationError(
            "Unable to read PDF file. The file may be corrupted. Try a different file or fill manually."
        )
```

**Source:** [How to Check File Size in Python](https://www.geeksforgeeks.org/python/how-to-check-file-size-in-python/), [pdfplumber Issue #681](https://github.com/jsvine/pdfplumber/issues/681), [CONTEXT.md (Error Handling decisions)](/.planning/phases/15-pdf-resume-parser/15-CONTEXT.md)

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Date parsing from text | Custom regex for all date formats | python-dateutil parser.parse(fuzzy=True) | Handles 100+ date formats, fuzzy text extraction, timezone awareness. Manual regex requires maintaining dozens of patterns for "Jan 2020", "2020-01", "January 2020 - Present", etc. |
| PDF encryption detection | Read file bytes and check PDF header flags | pdfplumber open() catches PDFPasswordIncorrect exception | PDF encryption is complex (40-bit RC4, 128-bit AES, permissions). pdfplumber's underlying pdfminer handles all encryption types. |
| File path validation | Manual os.path checks | questionary.path() with validate parameter | Provides autocomplete, tilde expansion, relative path resolution. Manual validation misses edge cases (symlinks, case sensitivity). |
| Name parsing from text | Regex for first/last name | Heuristic: First non-contact line + capitalization check | Names vary globally (single name, multiple last names, prefixes). Regex approach fails for "Mar√≠a Garc√≠a", "van der Berg". Heuristic is more robust. |
| UTF-8 handling | Manual encode/decode | Python 3 native UTF-8 strings + pdfplumber unicode_norm | Python 3 strings are Unicode by default. pdfplumber supports NFC/NFD/NFKC/NFKD normalization for consistent international character handling. |

**Key insight:** Resume parsing involves highly variable text formats. Use fuzzy parsing and heuristics over strict regex patterns. User validates extracted data in wizard, so 80% accuracy is acceptable‚Äîmanual fallback handles the rest.

## Common Pitfalls

### Pitfall 1: Assuming PDF Extraction Always Succeeds

**What goes wrong:** Wizard crashes when PDF parsing fails, forcing user to restart setup.

**Why it happens:** PDF formats vary wildly. Image-only PDFs, encrypted PDFs, corrupted files, and unusual layouts all cause extraction failures. Failure rate: 20-30% based on resume parsing research.

**How to avoid:**
- Wrap all PDF operations in try-except blocks
- Validate PDF before parsing (text-extractable check, size limit, encryption detection)
- Degrade gracefully to manual entry on any failure
- Never skip wizard completion path

**Warning signs:**
- User reports "Setup crashed after uploading resume"
- Logs show unhandled PDFSyntaxError or PDFPasswordIncorrect exceptions
- Wizard exits without saving profile.json

**Prevention code:**
```python
try:
    extracted_data = extract_resume_data(pdf_path)
except PDFValidationError as e:
    print(f"\n‚ùå {str(e)}\n")
    fallback_prompt = questionary.confirm(
        "Would you like to fill your profile manually?",
        default=True
    ).ask()
    if not fallback_prompt:
        return False
    extracted_data = {}
except Exception as e:
    print(f"\n‚ö†Ô∏è  PDF parsing failed: {e}")
    print("Continuing with manual entry...\n")
    extracted_data = {}
```

### Pitfall 2: Using Strict Regex for Variable Resume Formats

**What goes wrong:** Extraction works for 1-2 test resumes but fails in production for most users. Name extraction returns email address. Years of experience is None for valid resumes.

**Why it happens:** Resume formats are highly variable. "Software Engineer" vs "Sr. Software Engineer, Team Lead" vs "Software Engineer | Full Stack". Dates: "Jan 2020 - Present", "2020-2023", "01/2020 - Present", "January 2020 to December 2023".

**How to avoid:**
- Use fuzzy matching and heuristics over strict patterns
- Try multiple extraction strategies (explicit mention, calculated from dates)
- Accept partial success (extract what works, skip what fails)
- Use dateutil.parser.parse(fuzzy=True) for date flexibility
- Filter extracted values with sanity checks, not strict validation

**Warning signs:**
- Test coverage shows 95% pass rate, but production extraction rate is 40%
- Name field contains email or phone number
- Job titles include company names or locations
- Extracted skills include full sentences

**Prevention patterns:**
```python
# BAD: Strict regex requires exact format
name_pattern = r'^([A-Z][a-z]+)\s([A-Z][a-z]+)$'  # Fails for "Mary Jane Smith", "Jos√© Garc√≠a"

# GOOD: Heuristic checks multiple criteria
def _extract_name(text):
    lines = text.split('\n')
    for line in lines[:5]:
        if not re.search(r'@|\.com|http|\d{3}', line):  # Skip contact info
            if 2 <= len(line.split()) <= 5:  # Reasonable name length
                if line[0].isupper():  # Starts with capital
                    return line.strip()
    return None
```

### Pitfall 3: Not Validating Extracted Data Before Display

**What goes wrong:** Wizard shows garbage data as defaults. Years of experience = -5. Name = "EXPERIENCE". Skills list contains full paragraphs.

**Why it happens:** Regex patterns match text that looks structurally correct but semantically wrong. "5 years" in "Required: 5 years experience" gets parsed as candidate's experience. First line "PROFESSIONAL EXPERIENCE" looks like a name.

**How to avoid:**
- Sanity check extracted values before using as defaults (per CONTEXT.md decision)
- Validate data types: years must be numeric and positive
- Skip clearly invalid extractions (negative years, empty names, skills >50 chars)
- Don't enforce strict format patterns (user will edit in wizard)
- Log validation failures for debugging

**Warning signs:**
- User sees nonsensical default values in wizard
- Validation errors trigger immediately after PDF parsing
- Extracted "name" is a section header or contact detail
- Skills list contains full job descriptions

**Prevention code:**
```python
# Per CONTEXT.md: "Basic sanity checks before showing extracted data"
if key == 'years_experience' and isinstance(value, int) and value >= 0:
    prompt_kwargs['default'] = str(value)
elif key == 'name' and isinstance(value, str) and value.strip():
    # Additional check: name should be < 100 chars, not all caps
    if len(value) < 100 and not value.isupper():
        prompt_kwargs['default'] = value
elif key == 'skills' and isinstance(value, list):
    # Filter out overly long "skills" (likely full sentences)
    valid_skills = [s for s in value if len(s) < 50]
    if valid_skills:
        prompt_kwargs['default'] = ', '.join(valid_skills)
```

### Pitfall 4: Blocking Wizard on Missing pdfplumber Dependency

**What goes wrong:** Wizard crashes on import with "ModuleNotFoundError: No module named 'pdfplumber'" even when user chooses "Fill manually".

**Why it happens:** Unconditional import at module top: `import pdfplumber`. If pdfplumber not installed (dev environment, pip install failed), entire wizard module fails to load.

**How to avoid:**
- Use conditional import with try-except at module level
- Set PDF_SUPPORT flag to control feature availability
- Only import pdfplumber inside functions that use it
- Gracefully disable PDF upload option if library missing

**Warning signs:**
- Wizard fails to load on systems where pdfplumber installation failed
- Users who only want manual entry can't access wizard
- CI/CD pipeline breaks if pdfplumber omitted from test dependencies

**Prevention code:**
```python
# At top of pdf_parser.py
try:
    import pdfplumber
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False

# In wizard.py
def run_setup_wizard():
    # Only offer PDF upload if library available
    choices = []
    try:
        from .pdf_parser import PDF_SUPPORT
        if PDF_SUPPORT:
            choices.append("Upload resume PDF")
    except ImportError:
        pass

    choices.append("Fill manually")

    upload_choice = questionary.select(
        "How would you like to create your profile?",
        choices=choices
    ).ask()
```

## Code Examples

Verified patterns from research and prior implementation:

### Example 1: File Size Check Before Reading

```python
# Source: https://www.geeksforgeeks.org/python/how-to-check-file-size-in-python/
from pathlib import Path

def validate_file_size(file_path: Path, max_mb: int = 5) -> bool:
    """Check if file size is within limit before reading.

    Per CONTEXT.md: 5 MB maximum enforced.
    """
    max_bytes = max_mb * 1024 * 1024
    file_size = file_path.stat().st_size

    if file_size > max_bytes:
        raise ValueError(f"File size exceeds {max_mb} MB limit")

    return True
```

### Example 2: Questionary Path Prompt with Validation

```python
# Source: https://questionary.readthedocs.io/en/stable/pages/types.html
import questionary
from pathlib import Path

def prompt_for_pdf_path() -> str | None:
    """Prompt user for PDF file path with validation."""
    pdf_path_str = questionary.path(
        "Path to your resume PDF:",
        only_directories=False,  # Files only, not directories
        validate=lambda p: (
            Path(p).exists() and
            Path(p).suffix.lower() == '.pdf'
        ) or "Please enter a valid path to a PDF file",
        style=custom_style
    ).ask()

    return pdf_path_str
```

### Example 3: Fuzzy Date Parsing from Resume Text

```python
# Source: https://dateutil.readthedocs.io/en/stable/parser.html
from dateutil import parser as dateutil_parser
from datetime import datetime

def parse_work_date_range(text: str) -> tuple[datetime, datetime] | None:
    """Parse date range from resume work history.

    Handles formats:
    - "Jan 2020 - Present"
    - "2020-2023"
    - "March 2020 to December 2023"
    - "01/2020 - 06/2023"
    """
    import re

    # Split on dash/to
    parts = re.split(r'\s*[-‚Äì‚Äî]\s*|\s+to\s+', text, flags=re.IGNORECASE)

    if len(parts) != 2:
        return None

    start_str, end_str = parts

    try:
        # Parse start date with fuzzy=True (ignores non-date text)
        start_date = dateutil_parser.parse(start_str, fuzzy=True)

        # Handle "Present" / "Current"
        if re.search(r'present|current', end_str, re.IGNORECASE):
            end_date = datetime.now()
        else:
            end_date = dateutil_parser.parse(end_str, fuzzy=True)

        return (start_date, end_date)

    except (ValueError, TypeError):
        return None


def calculate_years_from_dates(date_ranges: list[tuple[datetime, datetime]]) -> int:
    """Calculate total years of experience from employment date ranges."""
    total_months = 0

    for start_date, end_date in date_ranges:
        months = (end_date.year - start_date.year) * 12
        months += (end_date.month - start_date.month)
        total_months += months

    return round(total_months / 12)
```

### Example 4: Detecting Image-Only PDFs

```python
# Source: https://github.com/jsvine/pdfplumber/discussions/717
import pdfplumber

def is_text_extractable_pdf(pdf_path: str) -> bool:
    """Check if PDF contains extractable text (not image-only).

    Per CONTEXT.md: "Text-extractable" = extract_text() returns non-empty string.
    """
    try:
        with pdfplumber.open(pdf_path, strict_metadata=False) as pdf:
            if len(pdf.pages) == 0:
                return False

            # Try first page
            first_page_text = pdf.pages[0].extract_text()

            # If None or empty string, PDF is image-only
            return bool(first_page_text and first_page_text.strip())

    except Exception:
        return False
```

### Example 5: UTF-8 Encoding for International Names

```python
# Source: https://github.com/jsvine/pdfplumber/issues/231
import pdfplumber

def extract_text_with_unicode_normalization(pdf_path: str) -> str:
    """Extract text from PDF with Unicode normalization for international names.

    Per PDF-07 requirement: Handle UTF-8 encoding for international names.
    """
    text = ""

    # Use unicode_norm='NFKC' for compatibility normalization
    # Converts composed characters to decomposed (e.g., "√©" ‚Üí "e" + combining accent)
    with pdfplumber.open(pdf_path, unicode_norm='NFKC') as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"

    return text
```

### Example 6: Atomic JSON Write Pattern (Existing)

```python
# Source: job_radar/wizard.py (existing implementation)
import json
import os
import tempfile
from pathlib import Path

def _write_json_atomic(path: Path, data: dict):
    """Write JSON file atomically with temp file + rename.

    Used by wizard for profile.json and config.json.
    Prevents partial writes on crash/interrupt.
    """
    path.parent.mkdir(parents=True, exist_ok=True)

    # Create temp file in same directory (same filesystem for atomic rename)
    fd, tmp_path = tempfile.mkstemp(
        dir=path.parent,
        prefix=path.name + ".",
        suffix=".tmp"
    )

    try:
        # Write JSON to temp file
        with os.fdopen(fd, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
            f.flush()
            os.fsync(f.fileno())

        # Atomic replace
        Path(tmp_path).replace(path)
    except:
        try:
            os.unlink(tmp_path)
        except:
            pass
        raise
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| PyPDF2 for text extraction | pdfplumber 0.11.9 | 2023 (PyPDF2 deprecated) | PyPDF2 development moved to pypdf. pdfplumber has superior layout handling for structured documents like resumes. |
| Manual regex for all date formats | python-dateutil fuzzy parsing | 2024+ (standard practice) | Handles 100+ date formats automatically. Reduces maintenance burden from dozens of regex patterns to single parser.parse() call. |
| spaCy/NLTK for resume parsing | Lightweight regex + heuristics | 2025-2026 trend | SpaCy models are 100MB+, overkill for simple field extraction. Regex sufficient when user validates in wizard. |
| Cross-platform bundler (cx_Freeze, py2exe) | PyInstaller 6.x | 2024+ (industry standard) | PyInstaller 6.x supports Python 3.8-3.14, handles dependencies automatically, works on all platforms. Latest release: 6.18.0 (Jan 2026). |

**Deprecated/outdated:**
- **PyPDF2:** Officially deprecated since 2023. Last release Dec 2022. Development moved to pypdf. Use pdfplumber for text extraction or pypdf for PDF manipulation.
- **pyresparser:** Depends on spaCy (100MB+ models) and NLTK. Adds complexity for minimal gain. User validates fields in wizard, so simple regex is sufficient.
- **Manual date regex patterns:** Maintaining patterns for "Jan 2020", "2020-01", "January 2020 - Present" is error-prone. Use python-dateutil.parser.parse(fuzzy=True).

## Open Questions

Things that couldn't be fully resolved:

1. **PyInstaller Hidden Imports for pdfplumber**
   - What we know: pdfplumber depends on pdfminer.six, which has transitive dependencies (cryptography, charset_normalizer). PyInstaller's static analysis may miss some.
   - What's unclear: Exact list of hidden imports needed for pdfplumber in PyInstaller builds.
   - Recommendation: Test build with pdfplumber, check for ImportError at runtime. Add hidden imports to job-radar.spec as needed. Likely candidates: `pdfminer.six`, `pdfminer.pdfparser`, `cryptography`.

2. **Optimal Regex Patterns for Job Titles**
   - What we know: Job titles vary widely ("Software Engineer", "Sr. SWE, Team Lead", "Full Stack Developer | Python"). Common keywords: engineer, developer, manager, analyst, designer.
   - What's unclear: Best heuristic for distinguishing titles from company names ("Amazon Web Services Engineer" vs "AWS | Engineer").
   - Recommendation: Start with keyword matching (engineer, developer, etc.) + line position heuristic (before dates). Iterate based on user feedback. Extraction accuracy goal: 70-80% (user edits in wizard).

3. **PDF Encryption Detection Without Opening**
   - What we know: pdfplumber.open() raises PDFPasswordIncorrect for encrypted PDFs. PyMuPDF has .needs_pass attribute.
   - What's unclear: Can we detect encryption before pdfplumber.open() to provide faster feedback?
   - Recommendation: Use pdfplumber.open() exception handling (simplest). Encryption check is fast (<100ms). Adding PyMuPDF dependency just for .needs_pass not worth complexity.

## Sources

### Primary (HIGH confidence)

- [pdfplumber PyPI](https://pypi.org/project/pdfplumber/) - Version 0.11.9, Python requirements, installation
- [pdfplumber GitHub](https://github.com/jsvine/pdfplumber) - Official documentation, examples, issues
- [python-dateutil Documentation](https://dateutil.readthedocs.io/en/stable/parser.html) - Parser API, fuzzy parsing
- [Questionary Documentation - Question Types](https://questionary.readthedocs.io/en/stable/pages/types.html) - Path prompt, validation
- [PyInstaller Manual 6.18.0](https://pyinstaller.org/en/stable/index.html) - Platform support, dependency bundling
- [STACK.md (v1.2.0)](/.planning/research/STACK.md) - Prior research on pdfplumber selection
- [ARCHITECTURE.md (v1.2.0)](/.planning/research/ARCHITECTURE.md) - PDF parser module pattern
- [Python Unicode HOWTO](https://docs.python.org/3/howto/unicode.html) - UTF-8 handling, encoding

### Secondary (MEDIUM confidence)

- [Identifying and decrypting encrypted PDFs | Medium](https://medium.com/quantrium-tech/encrypted-pdf-identification-and-decryption-using-python-dda8afdf9ae8) - PDF encryption detection techniques
- [Password protected PDF ¬∑ pdfplumber Issue #101](https://github.com/jsvine/pdfplumber/issues/101) - Encryption handling discussion
- [pdfplumber will be hung up on damaged PDF ¬∑ Issue #681](https://github.com/jsvine/pdfplumber/issues/681) - Corrupted PDF error handling
- [Is PDFPlumber suitable for scanned PDFs? | PDFPlumber](https://www.pdfplumber.com/is-pdfplumber-suitable-for-extracting-data-from-scanned-or-image-based-pdfs/) - Image-only PDF detection
- [How To Work with Unicode in Python | DigitalOcean](https://www.digitalocean.com/community/tutorials/how-to-work-with-unicode-in-python) - UTF-8 best practices
- [Getting File Sizes in Python | Medium](https://medium.com/@ryan_forrester_/getting-file-sizes-in-python-a-complete-guide-01293aaa68ef) - File size validation
- [How to Check File Size in Python | GeeksforGeeks](https://www.geeksforgeeks.org/python/how-to-check-file-size-in-python/) - os.path.getsize(), Path.stat()
- [Resume date format patterns | ResumeAdapter](https://www.resumeadapter.com/blog/ats-resume-formatting-rules-2026) - ATS date format standards
- [How to Format Dates on Resume | Enhancv](https://enhancv.com/blog/dates-on-resume/) - Common date format examples
- [Writing Your Own Resume Parser | OMKAR PATHAK](https://omkarpathak.in/2018/12/18/writing-your-own-resume-parser/) - Regex extraction patterns
- [Resume Parser with Regex | GitHub](https://github.com/sanketsarwade/Resume-Parser-using-Python) - Skills/titles extraction
- [Extract Skills from Resume Using Python | Affinda](https://www.affinda.com/blog/extract-skills-from-a-resume-using-python) - Skill extraction techniques

### Tertiary (LOW confidence - requires validation)

- Various Medium articles on resume parsing (not verified with official docs, approaches vary)
- Stack Overflow discussions on PDF text extraction (community wisdom, not authoritative)

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - pdfplumber and python-dateutil are well-documented, actively maintained, widely adopted. Prior research in STACK.md confirms selection.
- Architecture: HIGH - Patterns verified in existing wizard.py implementation. Atomic write, validators, questionary prompts all proven in production.
- Pitfalls: MEDIUM - Based on resume parsing literature and pdfplumber GitHub issues. Real-world failure rates estimated from research (20-30% PDF extraction failures).

**Research date:** 2026-02-10
**Valid until:** 30 days (2026-03-12) - Stack is stable, pdfplumber actively maintained but not fast-moving.

**Additional notes:**
- CONTEXT.md from /gsd:discuss-phase 15 provides locked implementation decisions. All patterns respect these constraints.
- Existing wizard.py provides proven patterns for validators, atomic writes, questionary integration.
- PyInstaller spec file shows current hidden imports‚Äîwill need updates for pdfplumber dependencies.
- Test patterns in test_wizard.py show validator testing strategy (MockDocument class, pytest.raises for validation errors).

---
phase: 03-test-suite
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - tests/conftest.py
  - tests/test_scoring.py
autonomous: true

must_haves:
  truths:
    - "pytest runs from project root and discovers all tests"
    - "Every _score_* function has at least one parametrized test with normal and edge cases"
    - "Dealbreaker detection tests cover exact match, substring match, and case-insensitive match triggering 0.0 score"
    - "Salary parsing tests cover $120k, $60/hr, $120,000, range formats, and Not listed"
    - "Shared conftest.py provides sample_profile and job_factory fixtures"
  artifacts:
    - path: "pyproject.toml"
      provides: "pytest configuration and dev dependency"
      contains: "[tool.pytest.ini_options]"
    - path: "tests/conftest.py"
      provides: "Shared fixtures for all test modules"
      exports: ["sample_profile", "job_factory"]
    - path: "tests/test_scoring.py"
      provides: "Parametrized tests for all scoring functions"
      min_lines: 100
  key_links:
    - from: "tests/conftest.py"
      to: "job_radar/sources.py"
      via: "JobResult import for job_factory"
      pattern: "from job_radar\\.sources import JobResult"
    - from: "tests/test_scoring.py"
      to: "job_radar/scoring.py"
      via: "Direct imports of private scoring functions"
      pattern: "from job_radar\\.scoring import"
    - from: "tests/test_scoring.py"
      to: "tests/conftest.py"
      via: "Fixture usage (job_factory, sample_profile)"
      pattern: "def test_.*\\(.*job_factory|sample_profile"
---

<objective>
Set up the pytest test framework and create comprehensive scoring tests covering all _score_* functions, dealbreaker detection, and salary parsing with parametrized edge cases.

Purpose: Establishes the test infrastructure (pytest config, shared fixtures) and validates the scoring engine -- the project's core value -- against regressions. Covers requirements TEST-07, TEST-01, TEST-02, TEST-03.
Output: Working pytest setup with conftest.py fixtures and test_scoring.py containing parametrized tests for all scoring components.
</objective>

<execution_context>
@/Users/coryebert/.claude/get-shit-done/workflows/execute-plan.md
@/Users/coryebert/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-test-suite/03-RESEARCH.md

@job_radar/scoring.py
@job_radar/sources.py
@job_radar/staffing_firms.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Configure pytest and create shared fixtures</name>
  <files>pyproject.toml, tests/conftest.py</files>
  <action>
1. Update pyproject.toml to add pytest config section:
   ```toml
   [tool.pytest.ini_options]
   testpaths = ["tests"]
   ```
   Do NOT add pytest to [project.dependencies] -- it is a dev tool, not a runtime dependency. The user runs `pip install pytest` separately.

2. Create `tests/conftest.py` with two fixtures:

   a. `sample_profile` fixture -- returns a dict matching the profile structure used by scoring.py:
      - core_skills: ["Python", "pytest", "FastAPI"]
      - secondary_skills: ["Docker", "PostgreSQL"]
      - target_titles: ["Senior Python Developer", "Backend Engineer"]
      - level: "senior"
      - years_experience: 7
      - arrangement: ["remote", "hybrid"]
      - location: "San Francisco, CA"
      - target_market: "SF Bay Area"
      - domain_expertise: ["fintech", "healthcare"]
      - dealbreakers: ["relocation required"]
      - comp_floor: 120000

   b. `job_factory` fixture -- returns a factory function `_make_job(**kwargs)` that creates JobResult instances with sensible defaults. Import JobResult from job_radar.sources. Defaults:
      - title: "Senior Python Developer"
      - company: "TestCorp"
      - location: "Remote"
      - arrangement: "remote"
      - salary: "$120k-$150k"
      - date_posted: "2026-02-08"
      - description: "Build scalable Python services with pytest and FastAPI"
      - url: "https://example.com/job/123"
      - source: "Test"
      - apply_info: ""
      - employment_type: "Full-time"
      - parse_confidence: "high"

3. Verify pytest is installed in the venv. If not, install it:
   ```bash
   .venv/bin/pip install pytest
   ```
  </action>
  <verify>
Run `.venv/bin/python -m pytest --collect-only` from the project root. It should discover 0 tests (no test files yet) but not error on configuration or fixture loading.
  </verify>
  <done>
pyproject.toml has [tool.pytest.ini_options] with testpaths = ["tests"]. tests/conftest.py exists with sample_profile and job_factory fixtures. pytest is installed and discovers the test directory without errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create parametrized scoring tests</name>
  <files>tests/test_scoring.py</files>
  <action>
Create `tests/test_scoring.py` with parametrized tests for every scoring function. Import private functions directly from job_radar.scoring. Use the job_factory and sample_profile fixtures from conftest.py.

**Required test functions (all use @pytest.mark.parametrize):**

1. `test_parse_salary_number(text, expected)` -- TEST-03
   Cases:
   - ("$120k", 120000.0)
   - ("$60/hr", 124800.0)  # 60 * 2080
   - ("$120,000", 120000.0)
   - ("$150000", 150000.0)  # no comma, bare number > 1000
   - ("Not listed", None)
   - ("", None)
   - (None, None)  # guard against None input
   - ("Competitive salary", None)  # non-numeric text
   - ("$100k-$150k", 100000.0)  # range: parses first number with k suffix

2. `test_check_dealbreakers(description, dealbreakers, expected)` -- TEST-02
   Cases:
   - Exact match: ("Must relocate to NYC", ["relocate"], "relocate")
   - Substring match: ("Requires on-site presence daily", ["on-site"], "on-site")
   - Case-insensitive: ("RELOCATION REQUIRED for role", ["relocation"], "relocation")
   - No match: ("Remote-friendly distributed team", ["on-site"], None)
   - Empty dealbreakers: ("Any description text here", [], None)
   Use job_factory to create job with custom description. Build profile dict with just dealbreakers key.

3. `test_score_skill_match(core_skills, secondary_skills, description, expected_min, expected_max)` -- TEST-01
   Cases:
   - All core match: (["Python", "FastAPI"], [], "Python and FastAPI developer", 4.0, 5.0)
   - No match: (["Rust", "Haskell"], [], "Python and FastAPI developer", 1.0, 1.5)
   - Secondary match: (["Python"], ["Docker"], "Python and Docker developer", 3.0, 5.0)
   - Empty skills: ([], [], "Python developer", 1.0, 1.0)  # ratio=0 -> score=1.0
   Use job_factory for job, build profile dict with core_skills/secondary_skills.
   Assert expected_min <= result["score"] <= expected_max (range check since exact values depend on ratio math).

4. `test_score_title_relevance(job_title, target_titles, expected_min)` -- TEST-01
   Cases:
   - Exact match: ("Senior Python Developer", ["Senior Python Developer"], 5.0)
   - Contained match: ("Senior Python Developer II", ["Senior Python Developer"], 4.0)
   - Word overlap: ("Python Software Engineer", ["Senior Python Developer"], 2.0)
   - No match: ("Marketing Manager", ["Senior Python Developer"], 1.0)
   - No target titles: ("Any Title", [], 3.0)  # default neutral
   Use job_factory with custom title. Assert result["score"] >= expected_min.

5. `test_score_seniority(job_title, level, years, expected_min, expected_max)` -- TEST-01
   Cases:
   - Match: ("Senior Developer", "senior", 7, 4.5, 5.0)
   - Mismatch: ("Junior Developer", "senior", 7, 1.0, 2.0)
   - Unknown level: ("Developer", "mid", 5, 3.0, 4.0)
   Use job_factory with custom title. Build profile with level and years_experience.

6. `test_score_location(arrangement, candidate_arrangements, expected_min)` -- TEST-01
   Cases:
   - Remote match: ("remote", ["remote", "hybrid"], 5.0)
   - Onsite wrong location: ("onsite", ["remote"], 1.0)
   - Unknown arrangement: ("unknown", ["remote"], 2.5)
   Use job_factory with custom arrangement/location.

7. `test_score_domain(description, domains, expected_min)` -- TEST-01
   Cases:
   - Domain match: ("fintech startup hiring", ["fintech"], 4.0)
   - No match: ("retail company hiring", ["fintech", "healthcare"], 3.0)
   - No domains set: ("any description", [], 3.0)

8. `test_score_response_likelihood(company, source, description, expected_min)` -- TEST-01
   Cases:
   - Staffing firm: ("Robert Half", "Dice", "standard listing", 4.0)
   - HN source: ("TestCo", "HN Hiring", "small team building", 3.0)
   - Default: ("BigCorp", "Dice", "standard listing", 2.5)

9. `test_score_job_dealbreaker_returns_zero(job_factory, sample_profile)` -- Integration
   Create job with "relocation required" in description. sample_profile has dealbreakers=["relocation required"]. Assert result["overall"] == 0.0 and result["dealbreaker"] is not None.

10. `test_score_job_overall_range(job_factory, sample_profile)` -- Integration
    Create a normal job, assert 1.0 <= result["overall"] <= 5.0.

**Important implementation notes:**
- Import scoring functions: `from job_radar.scoring import (_parse_salary_number, _check_dealbreakers, _score_skill_match, _score_title_relevance, _score_seniority, _score_location, _score_domain, _score_response_likelihood, score_job)`
- For functions that take a `job` parameter, use `job_factory(...)` to create the JobResult
- For functions that take a `profile` parameter, either use `sample_profile` fixture or build a minimal dict inline depending on what the test needs to control
- Use `ids=` parameter on parametrize for readable test output where helpful
- Each test asserts on the returned dict structure (score key for component scorers, overall for score_job)
  </action>
  <verify>
Run `.venv/bin/python -m pytest tests/test_scoring.py -v` from the project root. All tests must pass. Check that parametrized tests appear as individual items in the output (e.g., test_parse_salary_number[$120k-120000] appears separately from test_parse_salary_number[$60/hr-124800]).
  </verify>
  <done>
tests/test_scoring.py exists with parametrized tests covering: all _score_* functions (TEST-01), dealbreaker detection with exact/substring/case-insensitive matching (TEST-02), salary parsing with $120k/$60hr/$120,000/ranges/Not listed (TEST-03). All tests pass with `pytest -v`.
  </done>
</task>

</tasks>

<verification>
1. Run `cd "/Users/coryebert/Documents/Job Hunt Python/Project Folder/Job-Radar" && .venv/bin/python -m pytest tests/ -v` -- all tests pass, zero failures
2. Verify parametrized test count: `pytest --collect-only -q | tail -1` should show 30+ tests collected
3. Verify conftest fixtures load: `pytest --fixtures -q | grep -E "sample_profile|job_factory"` shows both fixtures
</verification>

<success_criteria>
- pytest runs from project root with zero configuration beyond pyproject.toml
- tests/conftest.py provides sample_profile and job_factory fixtures
- Every _score_* function in scoring.py has at least one parametrized test with normal and edge cases
- Dealbreaker tests verify exact match, substring, and case-insensitive match all return the dealbreaker string
- Salary parsing tests cover "$120k", "$60/hr", "$120,000", range formats, "Not listed", empty string, and None
- All tests pass with zero failures
</success_criteria>

<output>
After completion, create `.planning/phases/03-test-suite/03-01-SUMMARY.md`
</output>

---
phase: 07-interactive-setup-wizard
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - job_radar/wizard.py
  - pyproject.toml
autonomous: true

must_haves:
  truths:
    - "Wizard prompts for name, target job titles, core skills, location, and dealbreakers in that order"
    - "Wizard prompts for minimum score (1.0-5.0) and new-only filter preference"
    - "Required fields (name, skills, titles) reject empty input with inline error message"
    - "Optional fields (location, dealbreakers) allow skipping with Enter"
    - "User sees celebration summary of all answers before saving"
    - "Wizard writes profile.json and config.json atomically to platformdirs data directory"
    - "Mid-wizard back navigation allows user to type /back to return to previous question"
    - "Post-summary editing allows user to select and re-answer any field before saving"
  artifacts:
    - path: "job_radar/wizard.py"
      provides: "Complete setup wizard module"
      contains: "run_setup_wizard"
    - path: "pyproject.toml"
      provides: "questionary dependency declaration"
      contains: "questionary"
  key_links:
    - from: "job_radar/wizard.py"
      to: "job_radar/paths.py"
      via: "get_data_dir() for file output paths"
      pattern: "from .paths import get_data_dir"
---

<objective>
Create the interactive setup wizard module that collects user profile and preference data through sequential questionary prompts with validation, back navigation, and atomic JSON file output.

Purpose: This is the core wizard experience -- every prompt, validator, styling choice, and file write lives here. Phase 7's entire user-facing value depends on this module being complete and correct.

Output: job_radar/wizard.py containing run_setup_wizard() function, plus questionary added to pyproject.toml dependencies.
</objective>

<execution_context>
@/Users/coryebert/.claude/get-shit-done/workflows/execute-plan.md
@/Users/coryebert/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@.planning/phases/07-interactive-setup-wizard/07-CONTEXT.md
@.planning/phases/07-interactive-setup-wizard/07-RESEARCH.md

@job_radar/paths.py
@job_radar/config.py
@profiles/_template.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create wizard module with prompts, validators, back navigation, and file output</name>
  <files>job_radar/wizard.py, pyproject.toml</files>
  <action>
Create `job_radar/wizard.py` with the complete setup wizard. This is one cohesive module -- prompts, validators, styling, state management, file writing all belong together.

**Dependencies (pyproject.toml):**
Add `"questionary"` to the dependencies list in pyproject.toml (after "certifi").

**Validators (questionary Validator subclasses):**
- `NonEmptyValidator` -- rejects empty/whitespace-only input. Error: "This field cannot be empty"
- `CommaSeparatedValidator(min_items=1, field_name="item")` -- splits on comma, strips whitespace, checks min_items. Error: "Please enter at least {min_items} {field_name}(s)"
- `ScoreValidator` -- parses float, checks 1.0 <= value <= 5.0. Error: "Score must be a number between 1.0 and 5.0"

**Custom Style:**
Use questionary.Style with these tokens for cross-platform safe colors (ANSI basics, not hex):
- qmark: `'fg:cyan bold'`
- question: `'bold'`
- answer: `'fg:green bold'`
- instruction: `'fg:ansigray'` (example text color)

**Question definitions:**
Define questions as a list of dicts, each with: key, prompt_type ("text" or "confirm"), message, instruction (example text), validator, required (bool), default.

Question order per CONTEXT.md decisions (LOCKED):
1. name -- required, NonEmptyValidator, instruction: "e.g., John Doe"
2. titles -- required, CommaSeparatedValidator(min_items=1, field_name="job title"), instruction: "e.g., Software Engineer, Full Stack Developer"
3. skills -- required, CommaSeparatedValidator(min_items=1, field_name="skill"), instruction: "e.g., Python, JavaScript, React, AWS"
4. location -- optional, no validator, instruction: "e.g., Remote, New York, Hybrid (press Enter to skip)"
5. dealbreakers -- optional, no validator, instruction: "e.g., relocation required, on-site only (press Enter to skip)"

After profile questions, preference questions:
6. min_score -- text prompt, ScoreValidator, default="2.8" (per WIZ-08), instruction: "Enter a number from 1.0 to 5.0 (tip: 2.5-3.0 is a good starting point)"
7. new_only -- confirm prompt, default True: "Show only new jobs (not previously seen)?"

Per CONTEXT.md (LOCKED): "No default values -- all fields start empty, user must provide everything." This means:
- All 5 profile fields (name, titles, skills, location, dealbreakers) must NOT have any `default=` parameter passed to questionary. Fields start completely blank.
- Optional fields (location, dealbreakers) accept empty string (just pressing Enter) -- this is NOT a default value, it's accepting empty input. Do NOT pass `default=""` to questionary for these fields.
- Score (min_score) DOES get `default="2.8"` because WIZ-08 explicitly specifies "default 2.8" and score is a preference, not profile identity.
- new_only gets `default=True` because it's a preference with a sensible starting state.

**Mid-wizard back navigation (manual state management):**
Per CONTEXT.md user decision (LOCKED): "Back button navigation -- user can press a key (Ctrl+B or arrow up) to go back and change previous answers." This requires mid-wizard back navigation, not just post-summary editing.

Implementation -- while loop with index-based state:
- Use a while loop that iterates through questions by index (idx starts at 0)
- Maintain an `answers` dict that accumulates responses
- When re-visiting a question (going back), pre-fill the field with the previous answer using `default=answers.get(key, "")`
- Moving forward: `idx += 1` after storing answer
- Moving backward: `idx -= 1` (only if idx > 0)

**Back trigger mechanism (Claude's discretion per CONTEXT.md):**
Since questionary text prompts don't support custom keybindings natively, implement back navigation by checking for a special input value. After each prompt completes:
- If user types exactly "/back" (case-insensitive) as their answer, go back one question (idx -= 1, do NOT store the "/back" value)
- Display a hint at the wizard start: "Tip: Type /back at any prompt to return to the previous question."
- This is cross-platform compatible and doesn't require prompt_toolkit keybinding extensions

**Post-summary editing (ADDITIONAL to mid-wizard back):**
After all questions answered, show celebration summary, then ask "Save this configuration?" with options: "Save", "Edit a field", "Cancel"
- If "Edit a field": show questionary.select() with all field names, re-prompt that single field, return to summary
- If "Save": write files and return True
- If "Cancel": return False

This gives users TWO ways to edit: mid-flow via /back, and post-summary via "Edit a field".

**Section headers (per CONTEXT.md emoji decisions):**
Before question 1, print: "\nðŸ‘¤ Profile Information\n" + "-" * 40
Before question 6, print: "\nâš™ï¸  Search Preferences\n" + "-" * 40
Wizard header: "\n" + "=" * 60 + "\nðŸŽ¯ Job Radar - First Time Setup\n" + "=" * 60

**Celebration summary (per CONTEXT.md):**
After all questions, print:
```
âœ¨ All set! Here's your profile:
==================================================
ðŸ‘¤ Profile:
   Name: {name}
   Titles: {titles}
   Skills: {skills}
   Location: {location or '(not set)'}
   Dealbreakers: {dealbreakers or '(not set)'}

âš™ï¸  Preferences:
   Minimum Score: {min_score}
   New Jobs Only: {Yes/No}
==================================================
```

**Atomic JSON file writing:**
Implement `_write_json_atomic(path: Path, data: dict)` as a private function:
- path.parent.mkdir(parents=True, exist_ok=True)
- Create temp file in same directory with tempfile.mkstemp(dir=path.parent, prefix=path.name + ".", suffix=".tmp")
- Write JSON with indent=2, ensure_ascii=False
- os.fsync() before close
- Path(tmp_path).replace(path) for atomic rename
- Cleanup tmp on exception

**Profile JSON structure (must match existing scoring.py expectations):**
```json
{
  "name": "...",
  "target_titles": ["...", "..."],
  "core_skills": ["...", "..."],
  "location": "...",
  "dealbreakers": ["...", "..."]
}
```
Omit location key if empty. Omit dealbreakers key if empty list. This matches existing load_profile() expectations in search.py (required: name, target_titles, core_skills; optional: location, dealbreakers).

**Config JSON structure (must match existing KNOWN_KEYS in config.py):**
```json
{
  "min_score": 2.8,
  "new_only": true
}
```

**is_first_run() function:**
```python
def is_first_run() -> bool:
    from .paths import get_data_dir
    return not (get_data_dir() / "profile.json").exists()
```

**Ctrl+C handling:**
Use questionary's safe .ask() method (returns None on Ctrl+C). If any prompt returns None, ask confirmation to exit. If confirmed, return False from run_setup_wizard(). Do NOT raise KeyboardInterrupt -- let the caller handle the return value.

**run_setup_wizard() return value:**
- Returns True if wizard completed and files saved
- Returns False if user cancelled
- The caller (__main__.py, wired in Plan 02) uses this to decide whether to continue to search

**Validation failure: skip or retry flow (LOCKED per CONTEXT.md):**
Per user decision: "On validation failure: Offer to skip or retry -- show error, ask 'Try again or skip this field?'"

Implementation -- wrap each prompt in a helper function:
- For REQUIRED fields (name, titles, skills): questionary's built-in validator blocks until valid input. If user enters invalid input, questionary shows inline error and re-prompts automatically. No "skip" option for required fields -- only retry (questionary handles this natively).
- For OPTIONAL fields (location, dealbreakers): These have no validator (accept anything including empty), so skip/retry is not applicable in the current design. However, if a validator IS added to optional fields in the future, implement:
  ```python
  def prompt_with_skip_retry(message, instruction, validator, style):
      """Prompt with skip-or-retry on validation failure for optional fields."""
      while True:
          result = questionary.text(message, instruction=instruction, validate=validator, style=style).ask()
          if result is None:  # Ctrl+C
              return None
          return result  # Valid input accepted by questionary
      # If validation fails (questionary re-prompts), user can also just clear the field and press Enter to skip
  ```
- For SCORE field (min_score): ScoreValidator rejects out-of-range values. questionary re-prompts automatically. Since score has a default of "2.8", user can accept the default to move on.

The key insight: questionary's built-in validation loop already provides "retry" behavior. For optional fields that accept empty input, pressing Enter with nothing typed IS the "skip" action. The skip/retry UX emerges naturally from questionary's behavior + our field definitions.

**No autocomplete:** Per Claude's discretion (CONTEXT.md), skip skill autocomplete for v1.1 simplicity. Can add in future phase if user feedback requests it.
  </action>
  <verify>
Run: `cd "/Users/coryebert/Documents/Job Hunt Python/Project Folder/Job-Radar" && python -c "from job_radar.wizard import run_setup_wizard, is_first_run; print('Import OK')"` -- must print "Import OK" without errors.

Run: `cd "/Users/coryebert/Documents/Job Hunt Python/Project Folder/Job-Radar" && python -c "from job_radar.wizard import NonEmptyValidator, CommaSeparatedValidator, ScoreValidator; print('Validators OK')"` -- must print "Validators OK".

Run: `cd "/Users/coryebert/Documents/Job Hunt Python/Project Folder/Job-Radar" && python -c "import toml; d = toml.loads(open('pyproject.toml').read()); print('questionary' in str(d['project']['dependencies']))"` or manually verify pyproject.toml contains questionary.

Run existing test suite: `cd "/Users/coryebert/Documents/Job Hunt Python/Project Folder/Job-Radar" && python -m pytest tests/ -q` -- all existing tests must still pass (no regressions).
  </verify>
  <done>
wizard.py exists with run_setup_wizard(), is_first_run(), three validator classes, _write_json_atomic(), custom styling, section headers with emoji, mid-wizard /back navigation, celebration summary with post-summary edit-a-field loop, no default values on profile fields, score defaults to "2.8" per WIZ-08, and atomic JSON output. questionary is in pyproject.toml dependencies. All existing tests pass.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from job_radar.wizard import run_setup_wizard, is_first_run"` succeeds
2. `python -c "from job_radar.wizard import NonEmptyValidator, CommaSeparatedValidator, ScoreValidator"` succeeds
3. pyproject.toml dependencies list includes "questionary"
4. `python -m pytest tests/ -q` -- all existing tests pass
5. Manual code review: wizard.py contains all 7 question prompts in correct order, mid-wizard /back navigation via while loop, post-summary edit-a-field loop, no default= on profile fields, default="2.8" on min_score, atomic file writing, and proper profile/config JSON structures
</verification>

<success_criteria>
- wizard.py module importable with no errors
- All validators defined and functional
- Question order matches CONTEXT.md: Name -> Titles -> Skills -> Location -> Dealbreakers -> Score -> Filter
- Profile JSON matches scoring.py's required fields (name, target_titles, core_skills)
- Config JSON matches config.py's KNOWN_KEYS (min_score, new_only)
- Atomic file writing prevents corruption on interrupt
- questionary in pyproject.toml dependencies
- Existing test suite passes without regressions
</success_criteria>

<output>
After completion, create `.planning/phases/07-interactive-setup-wizard/07-01-SUMMARY.md`
</output>

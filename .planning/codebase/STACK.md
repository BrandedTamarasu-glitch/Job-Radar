# Technology Stack

**Analysis Date:** 2026-02-07

## Languages

**Primary:**
- Python 3.10+ - Core application; all source code in `job_radar/` directory

**Secondary:**
- Markdown - Report output format (Markdown files generated by `job_radar/report.py`)

## Runtime

**Environment:**
- Python 3.10+ (required by `pyproject.toml`)
- Cross-platform: macOS, Linux, Windows

**Package Manager:**
- pip - Dependency installation
- Lockfile: Not detected; dependencies pinned in `pyproject.toml` without version constraints

## Frameworks

**Core:**
- `argparse` (built-in) - CLI argument parsing in `job_radar/search.py`
- `dataclasses` - Job result model definition in `job_radar/sources.py` (`@dataclass JobResult`)
- `concurrent.futures` - Parallel query execution in `job_radar/sources.py` (ThreadPoolExecutor with 6 workers)

**HTTP & Parsing:**
- `requests` - HTTP client for fetching job listings across all sources (`job_radar/cache.py` line 10)
- `BeautifulSoup4` (bs4) - HTML parsing for Dice, HN Hiring, We Work Remotely (`job_radar/sources.py` imports)

**Testing:**
- Not detected

**Build/Dev:**
- `setuptools` - Build system (requires setuptools>=68.0 in `pyproject.toml`)
- `wheel` - Package distribution format

## Key Dependencies

**Critical:**
- `requests` (version unspecified) - Essential for HTTP fetching from all job sources (Dice, HN Hiring, RemoteOK, We Work Remotely)
  - Used in `job_radar/cache.py` for retry logic with exponential backoff (2.0x multiplier)
  - Handles timeouts (15s default) and 3 retries
- `beautifulsoup4` (version unspecified) - Required for parsing HTML from Dice, HN Hiring, and We Work Remotely sources
  - Selector patterns: `soup.select()`, `soup.select_one()` for DOM navigation

**Infrastructure:**
- Standard library modules: `json`, `logging`, `os`, `subprocess`, `urllib.parse`, `re`, `time`, `hashlib`, `datetime`

## Configuration

**Environment:**
- No .env file required - all configuration is profile-based JSON
- Environment configuration happens through CLI flags:
  - `--profile` (required) - Path to candidate profile JSON
  - `--from` / `--to` - Date range (defaults to 48 hours ago to today)
  - `--output` - Report directory (default: `results/`)
  - `--min-score` - Scoring threshold (default: 2.8)
  - `--verbose` / `-v` - Debug logging
  - `--no-cache` - Disable HTTP response caching
  - `--new-only` - Filter to new listings only
  - `--dry-run` - Preview queries without fetching

**Build:**
- `pyproject.toml` - PEP 517/518 configuration
  - Entry point: `job-radar = "job_radar.search:main"`
  - Build backend: `setuptools.build_meta`

## Platform Requirements

**Development:**
- Python 3.10 or higher
- pip (included with Python 3.10+)
- Virtual environment support (venv module, built-in)

**Production:**
- Cross-platform CLI deployment
- Automatic dependency installation via `job_radar/deps.py`:
  - Detects PEP 668 "externally-managed-environment" errors
  - Auto-creates venv and re-executes if system Python is locked
  - Checks for missing packages: `requests`, `beautifulsoup4`
- Output: Markdown report files written to `results/` directory
- Persistent storage: `.cache/` (HTTP responses), `results/tracker.json` (cross-run job dedup)

## Caching & Storage

**HTTP Caching:**
- Local filesystem cache in `.cache/` directory
- Cache entries: SHA256 hash of URL as filename (16 chars) â†’ JSON with timestamp and response body
- TTL: 4 hours (configurable via `_CACHE_MAX_AGE_SECONDS` in `job_radar/cache.py`)
- Bypass with `--no-cache` flag

**Job Tracking:**
- `results/tracker.json` - Persistent job deduplication and application status
- Tracks: seen jobs, application statuses, run history (last 90 days)
- Used to label results as "new" vs "previously seen"

---

*Stack analysis: 2026-02-07*
